[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex01/Hands-On_Ex1.html",
    "href": "Hands-On_Ex/Hands-On_Ex01/Hands-On_Ex1.html",
    "title": "1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "",
    "text": "Published: 14-Apr-2023"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex01/Hands-On_Ex1.html#learning-outcome",
    "href": "Hands-On_Ex/Hands-On_Ex01/Hands-On_Ex1.html#learning-outcome",
    "title": "1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.1 Learning Outcome",
    "text": "1.1 Learning Outcome\nWe will:\n\nlearn the basic principles and components of ggplot2\ngain hands-on experience plotting functional graphs ✌️"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex01/Hands-On_Ex1.html#getting-started",
    "href": "Hands-On_Ex/Hands-On_Ex01/Hands-On_Ex1.html#getting-started",
    "title": "1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.2 Getting Started",
    "text": "1.2 Getting Started\n\n1.2.1 Install and load the required r libraries\nLoad the tidyverse library. tidyverse is a collection of powerful and popular packages, such as ggplot2, dplyr, in R that are designed to help us work with and manipulate data in a consistent and efficient manner.\n\n\nShow the code\npacman::p_load(tidyverse)\n\n\n\n\n1.2.2 Import the data\nWe import the exam_data.csv data-set. This data-set contains the examination scores of a cohort of Primary 3 students from a local school.\nThere are a total of seven attributes.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE.\n\n\n\nShow the code\nexam_data <- read_csv('data/Exam_data.csv', show_col_types = FALSE )"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex01/Hands-On_Ex1.html#introduction-to-ggplot",
    "href": "Hands-On_Ex/Hands-On_Ex01/Hands-On_Ex1.html#introduction-to-ggplot",
    "title": "1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.3 Introduction to ggplot",
    "text": "1.3 Introduction to ggplot\nggplot is an R package for decoratively creating data-driven graphics based on The Grammar of Graphics.\n\n1.3.1 R Base Graphics Vs ggplot\nFirst, let us compare how R Graphics, the core graphical functions of Base R and ggplot plot a simple histogram.\n\nR Base Graphicsggplot\n\n\n\n\nShow the code\nhist(exam_data$MATHS)\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Maths scores\") + \n  ylab('Frequency') +\n  xlab('Maths score') +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\nBase graphics has a pen on paper model: we can only draw on top of the plot, we cannot modify or delete existing content. There is no (user accessible) representation of the graphics, apart from their appearance on the screen. Base graphics includes both tools for drawing primitives and entire plots. Base graphics functions are generally fast, but have limited scope.\nOn the other hand, ggplot2 has an underlying grammar, based on the Grammar of Graphics (see sections below), that allows us to compose graphs by combining independent components. This makes ggplot2 powerful. Rather than being limited to sets of pre-defined graphics, we can create novel graphics that are tailored to our specific problem."
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex01/Hands-On_Ex1.html#grammar-of-graphics",
    "href": "Hands-On_Ex/Hands-On_Ex01/Hands-On_Ex1.html#grammar-of-graphics",
    "title": "1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.4 Grammar of Graphics",
    "text": "1.4 Grammar of Graphics\nGrammar of Graphics is a general scheme for data visualization which breaks up graphs into semantic components such as scales and layers. It was introduced by Leland Wilkinson (1999) .\nIn brief, the grammar tells us that a graphic maps the data to the aesthetic attributes (colour, shape, size) of geometric objects (points, lines, bars). The plot may also include statistical transformations of the data and information about the plot’s coordinate system. Facetting can be used to plot for different subsets of the data. The combination of these independent components are what make up a graphic.\n\n1.4.1 A Layered Grammar of Graphics\nThe 7 layers are:\n\n\n\n\n\n\nData: Refers to the data-set being plotted\nAesthetics: Use the attributes of the data to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: Represent our data using visual elements such as points, bar or line.\nFacets: Split the data into subsets to create small multiples of the same graph (paneling, multiple plots).\nStatistics:Apply additional statistical transformations that summarise the data (e.g. mean, confidence intervals).\nCoordinates: Define the pane on which data is mapped on the graphic.\nTheme: Modify all non-data components of a plot, such as main title, sub-title, y-aixs title, legend, and background.\n\nThe purpose of each layer (or component) is further discussed below."
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex01/Hands-On_Ex1.html#the-data-layer",
    "href": "Hands-On_Ex/Hands-On_Ex01/Hands-On_Ex1.html#the-data-layer",
    "title": "1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.5 The Data Layer",
    "text": "1.5 The Data Layer\nLet us call the ggplot() function, with data argument pointing to the data-set to be used for plotting.\n\n\nShow the code\nggplot(data=exam_data)\n\n\n\n\n\nUnder the hood, a ggplot object is initialized using the data provided. We will need to include 2 other key layers - the aesthetic mappings and geometric layer - to see the plot.\n\n\n\n\n\n\nNote\n\n\n\nIf the data-set is not already a data.frame, it will be converted to one by using the fortify() function."
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex01/Hands-On_Ex1.html#the-aesthetic-layer",
    "href": "Hands-On_Ex/Hands-On_Ex01/Hands-On_Ex1.html#the-aesthetic-layer",
    "title": "1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.6 The Aesthetic Layer",
    "text": "1.6 The Aesthetic Layer\nThe aesthetic mappings take attributes of the data and and use them to influence the visual characteristics, such as position, colour, size, shape, or transparency, of the plot.\nAll aesthetics of a plot are specified in the aes() function call. In the later part of this document, we will see that each geom layer can have its own aes specification.\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x= MATHS))\n\n\n\n\n\nThe tick marks and label for the x-axis are displayed."
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex01/Hands-On_Ex1.html#the-geometric-layer",
    "href": "Hands-On_Ex/Hands-On_Ex01/Hands-On_Ex1.html#the-geometric-layer",
    "title": "1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.7 The Geometric Layer",
    "text": "1.7 The Geometric Layer\nGeometric objects are the actual marks we put on a plot. Examples include:\n\ngeom_point for drawing individual points (e.g., a scatter plot)\ngeom_line for drawing lines (e.g., for a line charts)\ngeom_smooth for drawing smoothed lines (e.g., for simple trends or approximations)\ngeom_bar for drawing bars (e.g., for bar, column charts)\ngeom_histogram for drawing binned values (e.g. a histogram)\ngeom_polygon for drawing arbitrary shapes\ngeom_map for drawing polygons in the shape of a map! (we can access the data to use for these maps by using the map_data() function).\n\n A plot must have at least one geom; there is no upper limit. We can add a geom to a plot using the ’+’ operator.\n\n1.7.1 Geometric Object: geom_bar\nYup, it’s a for a bar chart!\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n1.7.2 Geometric Object: geom_dotplot\nIn a dot plot, the width of a dot corresponds to the bin width (or maximum width, depending on the binning algorithm), and dots are stacked.\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nDanger\n\n\n\nThe y-axis is not very useful and can be misleading.\n\n\nTo address the above concern, we take the following steps:\n\nscale_y_continuous() is used to turn off the y-axis, and\nbinwidth argument is used to change the binwidth to 2.5.\n\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5) +      \n  scale_y_continuous(NULL,           \n                     breaks = NULL)  \n\n\n\n\n\n\n\n1.7.3 Geometric Object: geom_histogram\ngeom_histogram() is used to create a simple histogram by using values in MATHS field of exam_data.\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_histogram()       \n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that the default bin is 30.\n\n\n\n\n1.7.4 Modify a geometric object by changing geom()\nThe following arguments of the geom() function can be used:\n\nbins argument is used to change the number of bins to 20,\nfill argument is used to shade the histogram with light blue color, and\ncolor argument is used to change the outline colour of the bars in black\n\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\")  \n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThese changes are applied at the specific geom() layer and will not perpertuate when we include another geom() layer.\n\n\n\n\n\n1.7.5 Modify a geometric object by changing aes()\nWe can changes the interior colour of the histogram (i.e. fill) by using sub-group of aes().\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nggplot2 takes care of the details of converting data into aesthetics (e.g., ‘red’, ‘yellow’, ‘green’) with a scale. There is one scale for each aesthetic mapping in a plot. The scale is also responsible for creating a guide, an axis or legend, that allows us to read the plot, converting aesthetic values back into data values.\nIf we want to set an aesthetic to a fixed value, without scaling it, do so in the individual layer outside of aes(). Refer to section 1.7.4.\n\n\n\n\n\n1.7.6 Geometric Object: geom_density\ngeom-density() computes and plots kernel density estimate, which is a smoothed version of the histogram.\nIt is a useful alternative to the histogram for continuous data that comes from an underlying smooth distribution.\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_density()           \n\n\n\n\n\nWe can plot two kernel density lines by using colour or fill arguments of aes().\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()\n\n\n\n\n\n\n\n1.7.7 Geometric Object: geom_boxplot\ngeom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\n\n\nShow the code\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot()            \n\n\n\n\n\nNotches are indentation on the box-plot at the median value to help visually assess whether the medians of distributions differ. The notch indicates a confidence interval around the median, calculated using the median absolute deviation. If the notches of two box plots do not overlap, it suggests that the medians of the two groups are significantly different. We can show the indentation using the notch argument.\n\n\nShow the code\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)\n\n\n\n\n\n\n\n1.7.8 Geometric Object: geom_violin\ngeom_violin is designed for creating violin plot. With ordinary density curves (see section 1.7.6), it is difficult to compare more than just a few distributions because the lines visually interfere with each other. With a violin plot, it’s easier to compare several distributions since they’re placed side by side.\n\n\nShow the code\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()\n\n\n\n\n\n\n\n1.7.9 Geometric Object: geom_point\ngeom_point() is especially useful for creating scatterplot.\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()            \n\n\n\n\n\n\n\n1.7.10 Combine several geom objects\nFor instance, we can plot the data points on the boxplots by using both geom_boxplot() and geom_point().\n\n\nShow the code\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +                    \n  geom_point(position=\"jitter\", \n             size = 0.5)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex01/Hands-On_Ex1.html#the-statistics-layer",
    "href": "Hands-On_Ex/Hands-On_Ex01/Hands-On_Ex1.html#the-statistics-layer",
    "title": "1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.8 The Statistics Layer",
    "text": "1.8 The Statistics Layer\nThe Statistics functions statistically transform data, usually as some form of summary. For example:\n\nfrequency of values of a variable (bar graph)\n\na mean\na confidence limit\n\nThere are two ways to use these functions:\n\nadd a stat_() function and override the default geom, or\nadd a geom_() function and override the default stat.\n\n\n\n1.8.1 Working with the stat() function\nWe can use stat_summary() function to include the mean value on a boxplot.\n\n\nShow the code\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun =\"mean\",         \n               colour =\"red\",        \n               size=4)               \n\n\n\n\n\n\n\n1.8.2 Working with the geom() function\nWe can also use the geom() function to get the same result.\n\n\nShow the code\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun=\"mean\",           \n             colour =\"red\",          \n             size=4)          \n\n\n\n\n\n\n\n1.8.3 Add a best fit curve on a scatter-plot\nThe scatter-plot below shows the relationship of Maths and English grades of pupils. The interpretability of this graph can be improved by adding a best fit curve using the geom_smooth() function.\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(linewidth=0.5)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe default smoothing method used is loess (short for “locally weighted scatter-plot smoothing”). The loess method involves fitting a smooth curve to a scatter-plot of data points, where the curve is weighted to give more emphasis to nearby points and less emphasis to points that are far away.\n\n\nThe default smoothing method can be overridden as shown below. The “lm” method can be used to fit a straight line to a scatterplot of data points. This line represents the best linear approximation of the relationship between the variables and can be used to make predictions or estimate the effect of one variable on the other.\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex01/Hands-On_Ex1.html#the-facet-layer",
    "href": "Hands-On_Ex/Hands-On_Ex01/Hands-On_Ex1.html#the-facet-layer",
    "title": "1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.9 The Facet Layer",
    "text": "1.9 The Facet Layer\nFaceting generates small multiples (sometimes also called trellis plot), each displaying a different subset of the data. They are an alternative to aesthetics for displaying additional discrete variables. ggplot2 supports two types of factes, namely: facet_grid() and facet_wrap().\n\n1.9.1 Working with facet_wrap()\nfacet_wrap wraps a 1-d sequence of panels into 2-d. This is generally a better use of screen space than facet_grid because most displays are roughly rectangular.\nLet’s do a trellis plot using facet-wrap() for the maths score of each class.\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)\n\n\n\n\n\n\n\n1.9.1 Working with facet_grid()\nfacet_grid() forms a matrix of panels defined by row and column facetting variables. It is most useful when we have two discrete variables, and all combinations of the variables exist in the data.\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n  facet_grid(CLASS~.) +\n  theme(plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), \"cm\"))\n\n\n\n\n\nFrom the above, it’s now more apparent that the maths scores decrease as we move down from Class 3A to Class 3I."
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex01/Hands-On_Ex1.html#the-coordinates-layer",
    "href": "Hands-On_Ex/Hands-On_Ex01/Hands-On_Ex1.html#the-coordinates-layer",
    "title": "1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.10 The Coordinates Layer",
    "text": "1.10 The Coordinates Layer\nThere are two types of coordinate systems. Linear coordinate systems preserve the shape of geoms:\n\ncoord_cartesian(): the default Cartesian coordinate system, where the 2-d position of an element is given by the combination of the x and y positions.\ncoord_flip(): Cartesian coordinate system with x and y axes flipped.\ncoord_fixed(): Cartesian coordinate system with a fixed aspect ratio.\n\nOn the other hand, non-linear coordinate systems can change the shapes: a straight line may no longer be straight. The closest distance between two points may no longer be a straight line.\n\ncoord_map()/coord_quickmap()/coord_sf(): Map projections.\ncoord_polar(): Polar coordinates.\ncoord_trans(): Apply arbitrary transformations to x and y positions, after the data has been processed by the stat.\n\n\n1.10.1 Working with Coordinates\nBy the default, the bar chart of ggplot2 is in vertical form (i.e. column chart).\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\nWe can flip the horizontal bar chart into vertical bar chart by using coord_flip().\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\n1.10.2 Change the y- and x-axis range\nWe can use the coord_caatesian() function to fix both the y-axis and x-axis range from 0-100.\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex01/Hands-On_Ex1.html#the-theme-layer",
    "href": "Hands-On_Ex/Hands-On_Ex01/Hands-On_Ex1.html#the-theme-layer",
    "title": "1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.11 The Theme Layer",
    "text": "1.11 The Theme Layer\nThemes control elements of the graph not related to the data. For example:\n\nbackground colour\nsize of fonts\ngridlines\nlabels colour\n\nBuilt-in themes include: - theme_gray() (default) - theme_bw() - theme_classic()\nA list of theme can be found at this link. Each theme element can be conceived of as either a line (e.g. x-axis), a rectangle (e.g. graph background), or text (e.g. axis title).\n\n1.11.1 Working with theme\nA horizontal bar chart plotted using various themes.\ntheme_classic() is my favourite! 😜\n\ntheme_gray()theme_bw()theme_classic()theme_minimal()\n\n\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex01/Hands-On_Ex1.html#reference",
    "href": "Hands-On_Ex/Hands-On_Ex01/Hands-On_Ex1.html#reference",
    "title": "1 A Layered Grammar of Graphics: ggplot2 methods",
    "section": "1.12 Reference",
    "text": "1.12 Reference\n\nHadley Wickham (2023) ggplot2: Elegant Graphics for Data Analysis. Online 3rd edition.\nWinston Chang (2013) R Graphics Cookbook 2nd edition. Online version.\nHealy, Kieran (2019) Data Visualization: A practical introduction. Online version\nLearning ggplot2 on Paper – Components\nLearning ggplot2 on Paper – Layer\nLearning ggplot2 on Paper – Scale\n\n\n\\(**That's\\) \\(all\\) \\(folks!**\\)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex02/Hands-On_Ex2.html",
    "href": "Hands-On_Ex/Hands-On_Ex02/Hands-On_Ex2.html",
    "title": "2 Beyond ggplot2 Fundamentals",
    "section": "",
    "text": "Published: 20-Apr-2023\nModified: 27-Apr-2023"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex02/Hands-On_Ex2.html#learning-outcome",
    "href": "Hands-On_Ex/Hands-On_Ex02/Hands-On_Ex2.html#learning-outcome",
    "title": "2 Beyond ggplot2 Fundamentals",
    "section": "2.1 Learning Outcome",
    "text": "2.1 Learning Outcome\nWe will learn to plot charts that are beyond the out-of-the-box offerings from ggplot2. We will explore how to customize and extend ggplot2 with new:\n\nAnnotations\nThemes\nComposite plots"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex02/Hands-On_Ex2.html#getting-started",
    "href": "Hands-On_Ex/Hands-On_Ex02/Hands-On_Ex2.html#getting-started",
    "title": "2 Beyond ggplot2 Fundamentals",
    "section": "2.2 Getting Started",
    "text": "2.2 Getting Started\n\n2.2.1 Install and load the required r libraries\nInstall and load the the required R packages. The name and function of the new packages that will be used for this exercise are as follow:\n\nggrepel: provides a way to prevent labels from overlapping in ggplot2 plots\nggthemes: provides a set of additional themes, geoms and scales for ggplot2\nhrbrthemes👍🏾: provides another set of visually appealing themes and formatting options for ggplot2\npatchwork👍🏾: provides a way to combine multiple ggplot2 plots into a single figure\n\n\n\nShow the code\npacman::p_load(tidyverse, patchwork, \n               ggthemes, hrbrthemes,\n               ggrepel)\n\n\n\n\n2.2.2 Import the data\nWe will be using the same exam scores data-set that was featured in my Hands-On Ex 1.\n\n\nShow the code\nexam_data <- read_csv('data/Exam_data.csv', show_col_types = FALSE )"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex02/Hands-On_Ex2.html#beyond-ggplot2-annotation",
    "href": "Hands-On_Ex/Hands-On_Ex02/Hands-On_Ex2.html#beyond-ggplot2-annotation",
    "title": "2 Beyond ggplot2 Fundamentals",
    "section": "2.3 Beyond ggplot2 Annotation",
    "text": "2.3 Beyond ggplot2 Annotation\nOne challenge in plotting statistical graph is annotation, especially with large number of data points. The data points overlap and this leads to an ugly chart.\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n2.3.1 Working with ggrepel package\nggrepel is an extension of ggplot2 package which provides geoms for ggplot2 to repel overlapping text. We simply replace geom_text() by geom_text_repel() and geom_label() by geom_label_repel().\ngeom_text_repel() adds text directly to the plot. geom_label_repel() draws a rectangle underneath the text, making it easier to read.\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex02/Hands-On_Ex2.html#beyond-ggplot2-themes",
    "href": "Hands-On_Ex/Hands-On_Ex02/Hands-On_Ex2.html#beyond-ggplot2-themes",
    "title": "2 Beyond ggplot2 Fundamentals",
    "section": "2.4 Beyond ggplot2 Themes",
    "text": "2.4 Beyond ggplot2 Themes\nggplot2 comes with eight built-in themes, they are: theme_gray(), theme_bw(), theme_classic(), theme_dark(), theme_light(), theme_linedraw(), theme_minimal(), and theme_void(). 4 of these themes were featured in my Hands-On-Ex1 page.\n\n\nShow the code\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  theme_gray() +  \n  ggtitle(\"Distribution of Maths scores [theme_gray()]\") \n\n\n\n\n\n\n\n\n\n\n\nFor facet or small multiple plots\n\n\n\nConsider using theme_gray(), theme_bw() or theme_light() as they offer bounded axis which helps to compartmentalize the different plots.\n\n\n\n2.4.1 Working with ggthemes package\nggthemes provides ‘ggplot2’ themes that replicate the look of plots by Edward Tufte, Stephen Few, Fivethirtyeight, The Economist, ‘Stata’, ‘Excel’, and The Wall Street Journal, among others.\nCheck out some of the available themes below 👇🏼.\n\nTufteEconomist(Stephen) Few 👍🏾FivethirtyeightGDocs 👍🏾Highcharts 👍🏾\n\n\n\n\nShow the code\np1 <- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\np1 + theme_tufte()\n\n\n\n\n\n\n\n\n\nShow the code\np1 +theme_economist() + scale_colour_economist()\n\n\n\n\n\n\n\n\n\nShow the code\np1 + theme_few() + scale_colour_few()\n\n\n\n\n\n\n\n\n\nShow the code\np1 + scale_color_fivethirtyeight(\"cyl\") + theme_fivethirtyeight()\n\n\n\n\n\n\n\n\n\nShow the code\np1 + theme_gdocs() + scale_color_gdocs()\n\n\n\n\n\n\n\n\n\nShow the code\np1 + theme_hc() + scale_colour_hc()\n\n\n\n\n\n\n\n\nThe package also provides some extra geoms and scales for ‘ggplot2’. Consult this vignette to learn more.\n\n\n2.4.2 Working with hrbthems package\nhrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\n\n\nShow the code\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\n\nThe second goal centers around productivity for a production workflow. In fact, this “production workflow” is the context for where the elements of hrbrthemes should be used. It allows us, the data analysts, to focus on the analysis while the package works behind the scene to produce an elegant chart. Consult this vignette to learn more.\n\n\nShow the code\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18, \n              base_size = 15, \n              grid = \"Y\") \n\n\n\n\n\n\n\n\n\n\n\nTweaking the arguments in the theme_ipsum() function\n\n\n\n\naxis_title_size argument is used to increase the font size of the axis title to 18,\nbase_size argument is used to increase the default axis label to 15, and\ngrid argument is used to remove the x-axis grid lines."
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex02/Hands-On_Ex2.html#beyond-ggplot2-facet",
    "href": "Hands-On_Ex/Hands-On_Ex02/Hands-On_Ex2.html#beyond-ggplot2-facet",
    "title": "2 Beyond ggplot2 Fundamentals",
    "section": "2.5 Beyond ggplot2 facet",
    "text": "2.5 Beyond ggplot2 facet\nIt is not unusual that multiple graphs are required to tell a compelling visual story. There are several ggplot2 extensions provide functions to compose a figure with multiple graphs. In this section, we will learn how to create a composite plot by combining multiple graphs. First, let us create three statistical graphs.\n\n\nShow the code\np1 <- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\np2 <- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\np3 <- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\np1\n\n\n\n\n\nShow the code\np2\n\n\n\n\n\nShow the code\np3\n\n\n\n\n\n\n2.5.1 Creating Composite Graphics with pathwork package\nThere are several ggplot2 extensions which provide functions to compose figure with multiple graphs. In this section, we are going to explore patchwork.\nThe patchwork package has a very simple syntax where we can create layouts super easily.\n\nBasic layout: Placing 2 plots side-by-sideDefault layout: Grid SquareChange layout: use plot_layout() function\n\n\n\n\nShow the code\np1 + p2\n\n\n\n\n\n\n\n\n\nShow the code\np1 + p2 + p3 + p1\n\n\n\n\n\n\n\n\n\nShow the code\np1 + p2 + p3 + plot_layout(nrow = 3, byrow = FALSE)\n\n\n\n\n\n\n\n\nWe can use | to place the plots beside each other, while / will stack them\n\n\nShow the code\np1 + p2 / p3\n\n\n\n\n\n\n\nShow the code\n(p1 / p2) | p3\n\n\n\n\n\npatchwork also provides auto-tagging capabilities, in order to identify subplots in text\n\n\nShow the code\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = '1')\n\n\n\n\n\nWe can apply themes to the charts\n\n\nShow the code\npatchwork <- (p1 / p2) | p3\npatchwork & theme_economist()\n\n\n\n\n\nBeside providing functions to place plots next to each other based on the provided layout. With inset_element() of patchwork, we can place one or several plots or graphic elements freely on top of another plot.\n\n\nShow the code\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1.)\n\n\n\n\n\nRefer to Plot Assembly to learn more about arranging charts using patchwork."
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex02/Hands-On_Ex2.html#references",
    "href": "Hands-On_Ex/Hands-On_Ex02/Hands-On_Ex2.html#references",
    "title": "2 Beyond ggplot2 Fundamentals",
    "section": "2.6 References",
    "text": "2.6 References\n\nPatchwork R package goes nerd viral\nggrepel\nggthemes\nhrbrthemes\nggplot tips: Arranging plots\nggplot2 Theme Elements Demonstration\nggplot2 Theme Elements Reference Sheet\n\n\n\\(**That's\\) \\(all\\) \\(folks!**\\)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex03/Hands-On_Ex3a.html",
    "href": "Hands-On_Ex/Hands-On_Ex03/Hands-On_Ex3a.html",
    "title": "3 Interactive Data Visualisation with R",
    "section": "",
    "text": "Published: 25-Apr-2023"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex03/Hands-On_Ex3a.html#learning-outcome",
    "href": "Hands-On_Ex/Hands-On_Ex03/Hands-On_Ex3a.html#learning-outcome",
    "title": "3 Interactive Data Visualisation with R",
    "section": "3.1 Learning Outcome",
    "text": "3.1 Learning Outcome\nWe will learn to create interactive visuals"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex03/Hands-On_Ex3a.html#getting-started",
    "href": "Hands-On_Ex/Hands-On_Ex03/Hands-On_Ex3a.html#getting-started",
    "title": "3 Interactive Data Visualisation with R",
    "section": "3.2 Getting Started",
    "text": "3.2 Getting Started\n\n3.2.1 Install and load the required r libraries\nInstall and load the the required R packages. The name and function of the new packages that will be used for this exercise are as follow:\n\nggiraph: allows interactive graphics to be created using ggplot2\nplotly: creates interactive, web-based graphs using the Plotly.js JavaScript library\nDT: creates interactive tables using the DataTables JavaScript library. It allows data to be displayed in a table with features such as sorting, filtering, pagination, and searching.\n\n\n\nShow the code\npacman::p_load(tidyverse, patchwork, \n               ggiraph, plotly,\n              DT)\n\n\n\n\n3.2.2 Import the data\nWe will be using the same exam scores data-set that was featured in my Hands-On Ex 1.\n\n\nShow the code\nexam_data <- read_csv('data/Exam_data.csv', show_col_types = FALSE )"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex03/Hands-On_Ex3a.html#interactive-data-visualisation",
    "href": "Hands-On_Ex/Hands-On_Ex03/Hands-On_Ex3a.html#interactive-data-visualisation",
    "title": "3 Interactive Data Visualisation with R",
    "section": "3.3 Interactive Data Visualisation",
    "text": "3.3 Interactive Data Visualisation\n\n3.3.1 Working with ggiraph package\nggiraph is an htmlwidget and a ggplot2 extension. In ggplot2, interactivity can be added to a plot through the use of ggplot geometries. There are 3 arguments that can be used to enable interactivity in ggplot geometries:\n\ntooltip: To display a tooltip when the mouse is hovered over elements of the plot. Tooltips can be customized to include any information that is relevant to the plot.\nonclick: To specify an embedded JavaScript function that is executed when chart element is clicked.\ndata_id: To link a graph element to a record via a data_id. The data_id is a unique identifier for each record in the data, and it is used to enable interactivity between the plot and other components of the application.\nWhen used within a Shiny application, elements associated with an id (data_id) can be selected and manipulated on the client and server. The list of selected values will be stored in in a reactive value named [shiny_id]_selected.\n\n\n3.3.1.1 The tooltip argument\nFirst, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Next, girafe() of ggiraph is used to create an interactive Scalable Vector Graphics (SVG) object to display the plot on a html page.\n\n\n\n\n\n\nWhat is a SVG?\n\n\n\nSVG is an XML-based format that is commonly used for web graphics and interactive visualizations because it allows graphics to be resized without losing quality.\n\n\n👇Interactivity: By hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\n\nShow the code\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    #  Specifies that the dots will be stacked on top of each other when they overlap\n    stackgroups = TRUE, \n    binwidth = 1,\n    # Specifies the method for plotting the dot plot\n    method = \"histodot\") +\n  # NULL: Specifies that the y-axis label will be blank.\n  # breaks = NULL: Specifies that no tick marks will be displayed on the y-axis\n  scale_y_continuous(NULL, \n                     breaks = NULL)\n\ngirafe(\n  # Specifies the ggplot2 plot p that will be converted to an interactive plot using girafe\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\n\nDisplay more information on tooltip\nHere, we included the student’s class in the tooltip.\nThe first three lines of codes below create a new field called tooltip. Text data in the ID and CLASS fields are assigned to the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 8.\n👇Interactivity: The student’s ID and class are not displayed in the tooltip.\n\n\nShow the code\nexam_data$tooltip <- c(paste0(     #<<\n  \"Name = \", exam_data$ID,         #<<\n  \"\\n Class = \", exam_data$CLASS)) #<<\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), #<<\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\n\n\n\n\n\nCustomise Tooltip style\nWe can use opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\n👇Check out the formatting style of the tooltip of the 2 sample charts below ,\n\nexam_datamtcars data\n\n\n\n\nShow the code\ntooltip_css <- \"background-color:white; #<<\nfont-style:bold; color:black;\" #<<\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #<<\n    opts_tooltip(    #<<\n      css = tooltip_css)) #<<\n)                             \n\n\n\n\n\n\n\n\n\n\nShow the code\ndataset <- mtcars\ndataset$carname = row.names(mtcars)\n\ngg <- ggplot(\n  data = dataset,\n  mapping = aes(x = wt, y = qsec, color = disp,\n                tooltip = carname, data_id = carname) ) +\n  geom_point_interactive() + theme_minimal()\n\nx <- girafe(ggobj = gg)\nx <- girafe_options(x,\n  opts_tooltip(opacity = .7,\n    offx = 20, offy = -10,\n    use_fill = TRUE, use_stroke = TRUE,\n    delay_mouseout = 1000) )\nx\n\n\n\n\n\n\n\n\n\nRefer to this page to learn more about how to customise girafe animations\nDisplay statistics on tooltip\nIn the following example, a function is used to compute the standard error of the mean math scores. The derived statistics are then displayed in the tooltip.\n🖱️Mouse over the chart to check out the tooltip!\n\n\nShow the code\ntooltip <- function(y, ymax, accuracy = .01) {   #<<\n  mean <- scales::number(y, accuracy = accuracy) #<<\n  sem <- scales::number(ymax - y, accuracy = accuracy) #<<\n  paste(\"Mean maths scores (with standard error):\\n\", mean, \"+/-\", sem) #<<\n} #<<\n\n# Create graph\ngg_point <- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  #<<  after_stat() function specifies that the tooltip should be calculated after the summary statistics are calculated.\n                     tooltip(y, ymax))),  #<<\n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  #<<\n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\n# Generate SVG object\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\n\n3.3.1.2 The onclick argument\nonclick argument of ggiraph provides hotlink interactivity on the web. Web document link with a data object will be displayed on the web browser upon mouse click.\n\n\nShow the code\nexam_data$onclick <- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              #<<\n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                                                                \n\n\n\n\n\n\n\n\n3.3.1.3 The data_id argument\nWe assign the data_id argument to CLASS and when we mouse over a particular student in the chart below, the fellow classmates will also be highlighted.\n🖱️ Mouse over the chart to check out the hover effect!\n\n\nShow the code\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             #<<\n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\n\n\n\n\n\nThe default color of hover_css = “fill:orange;”\nCustomise the hover effect\nCSS codes are used to change the highlighting effect.\n🖱️ Mouse over the chart to check out the new hover effect!\n\n\nShow the code\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        #<<\n    opts_hover(css = \"fill: red;\"),  #<<\n    opts_hover_inv(css = \"opacity:0.2;\") #<<\n  )                                      #<<  \n)                                        \n\n\n\n\n\n\nCombine use of tooltip and data_id arguments\nThere are times when we want to combine tooltip and hover effect on an interactive statistical graph. In the following chart, elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\nShow the code\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, #<<\n        data_id = CLASS),#<<              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: red;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\n\n\n\n3.3.1.4 Coordinated multiple views with ggiraph\nWhen a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the different plots.\npatchwork function will be used inside girafe() function to create the interactive coordinated multiple views.\n\n\n\nShow the code\np1 <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS,\n        data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + #<<\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 <- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS,\n        data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + #<<\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 / p2), #<<\n       width_svg = 6,\n       height_svg = 6,\n       options = list(\n         opts_hover(css = \"fill: orange;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\n\n\n\n\n\n\n\n\n3.3.2 Working with plotly package\n\nPlotly’s R graphing library creates interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics.\nDifferent from other plotly platform, plot.R is free and open source.\n\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n\n3.3.2.1 Create an interactive scatter plot: plot_ly() function\nThe graph below is plotted using plot_ly().\n\n\nShow the code\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\n\n\n\n\n\nIn the next plot, the color argument is mapped to a qualitative visual variable (i.e. RACE). We can hide/unhide the data points for each race by click on their label in the legend.\n\n\nShow the code\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE) #<<\n\n\n\n\n\n\n\ncolors argument is used to change the default colour palette to ColorBrewer colour palette.\n\n\n\nShow the code\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE, \n        colors = \"Set1\") #<<\n\n\n\n\n\n\n\nWe can also customise our own colour scheme and assign it to the colors argument.\n\n\n\nShow the code\npal <- c(\"red\", \"purple\", \"blue\", \"green\") #<<\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE, \n        colors = pal) #<<\n\n\n\n\n\n\n\ntext argument is used to change the default tooltip.\n\n\n\nShow the code\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS,\n        text = ~paste(\"Student ID:\", ID,     #<<\n                      \"<br>Class:\", CLASS),  #<<\n        color = ~RACE, \n        colors = \"Set1\")\n\n\n\n\n\n\n\nlayout argument is used to update the chart title and axes limit.\n\n\n\nShow the code\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS,\n        text = ~paste(\"Student ID:\", ID,     \n                      \"<br>Class:\", CLASS),  \n        color = ~RACE, \n        colors = \"Set1\") %>%\n  layout(title = 'English Score versus Maths Score ', #<<\n         xaxis = list(range = c(0, 100)),             #<<\n         yaxis = list(range = c(0, 100)))             #<<\n\n\n\n\n\n\nTo learn more about layout, visit this link.\n\n\n3.3.2.2 Create an interactive scatter plot: ggplotly() funciton\nWe just need to include the original ggplot2 graph in the ggplotly() function.\n\n\nShow the code\np <- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(dotsize = 1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p) #<<\n\n\n\n\n\n\n3.3.2.3 Coordinated Multiple Views with plotly\n\nWe use subplot() of plotly package to place two scatterplots side-by-side.\n\n\n\nShow the code\np1 <- ggplot(data=exam_data, \n              aes(x = MATHS,\n                  y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 <- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),            #<<\n        ggplotly(p2))            #<<\n\n\n\n\n\n\n\nWe use the highlight_key() of plotly package to coordinate the selection of data points across two scatterplots.\n\n🖱️Click on the data point of one of the charts and we will see the same data point being highlighted in the other chart\n\n\nShow the code\nd <- highlight_key(exam_data)  #<<\n\np1 <- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 <- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\n\n\n\n\n\n\n\n\nHow highlight_key() function works\n\n\n\n\nThe function creates an object of class crosstalk::SharedData.\nVisit this link to learn more about crosstalk\n\n\n\n\n\n\n3.3.3 Working with crosstalk package\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\n3.3.3.1 Interactive Data Table: DT package\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\n\nShow the code\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\n\n\n3.3.3.2 Linked brushing: crosstalk method\nThings to note when implementing coordinated brushing:\n\nhighlight() is a function of plotly package. It sets a variety of options for brushing (i.e., highlighting) multiple plots. These options are primarily designed for linking multiple plotly graphs, and may not behave as expected when linking plotly to another htmlwidget package via crosstalk. In some cases, other htmlwidgets will respect these options, such as persistent selection in leaflet.\nbscols() is a helper function of crosstalk package. It makes it easy to put HTML elements side by side. It can be called directly from the console but is especially designed to work in an R Markdown document.\n\n👇Select a cluster of points from the scatterplot and the data table below will return the records of the selected data points\n\n\nShow the code\nd <- highlight_key(exam_data) \n\np <- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg <- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d),\n                  widths = 12)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex03/Hands-On_Ex3a.html#reference",
    "href": "Hands-On_Ex/Hands-On_Ex03/Hands-On_Ex3a.html#reference",
    "title": "3 Interactive Data Visualisation with R",
    "section": "3.4 Reference",
    "text": "3.4 Reference\n\n3.4.1 ggiraph\nThis link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to interactive graphs for Swiss Olympians - the solo specialists.\n\n\n\n3.4.2 plotly for R\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels\n\n\n\\(**That's\\) \\(all\\) \\(folks!**\\)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex03/Hands-On_Ex3b.html",
    "href": "Hands-On_Ex/Hands-On_Ex03/Hands-On_Ex3b.html",
    "title": "4 Animated Statistical Graph with R",
    "section": "",
    "text": "(First Published: 26-Apr-2023)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex03/Hands-On_Ex3b.html#learning-outcome",
    "href": "Hands-On_Ex/Hands-On_Ex03/Hands-On_Ex3b.html#learning-outcome",
    "title": "4 Animated Statistical Graph with R",
    "section": "4.1 Learning Outcome",
    "text": "4.1 Learning Outcome\nWhen telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. We will learn to create animated data visualisation. At the same time, we will also learn to reshape, process, wrangle and transform the data-set.\n\n4.1.1 Basic concept of animation\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot, which is built using a relevant subset of the data-set. Motion (and the animated effect) appears when the stitched plots are displayed sequentially.\n\n\n\n4.1.2 Terminologies\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminologies that will be used:\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, we can specify the duration of each frame, the easing function used to transit between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nWhen do we use animated graphs?\n\n\n\nBefore we start making animated graphs, we should first ask ourselves: Does it makes sense to go through the effort? If we are conducting an exploratory data analysis, a animated graphic may not be worth the time investment. However, if we are giving a presentation, a few well-placed animated graphics can help an audience connect with our topic remarkably better than static counterparts."
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex03/Hands-On_Ex3b.html#getting-started",
    "href": "Hands-On_Ex/Hands-On_Ex03/Hands-On_Ex3b.html#getting-started",
    "title": "4 Animated Statistical Graph with R",
    "section": "4.2 Getting Started",
    "text": "4.2 Getting Started\n\n4.2.1 Install and load the required r libraries\nInstall and load the the required R packages. The name and function of the new package that will be used for this exercise are as follow:\n\ngganimate: creates animated graphics, such as line charts, bar charts, and maps, by specifying a series of frames with data and aesthetics that change over time\ngifski: converts images to GIF animations using pngquant’s efficient cross-frame palettes and temporal dithering with thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\nreadxl: makes it easy to get data out of Excel and into R\n\n\n\nShow the code\npacman::p_load(tidyverse,plotly,gganimate, gifski, gapminder, gapminder,readxl)\n\n\n\n\n4.2.2 Import the data\nThe Data worksheet from GlobalPopulation Excel workbook will be used. We will use the following functions to process the data-set:\n\nread_xls() of readxl package is used to import the Excel worksheet.\nmutate_if() of dplyr package is used to a subset of columns in a data frame based on a logical condition\nmutate() of dplyr package is used to convert data values of Year field into integer.\n\n\n\nShow the code\ncol <- c(\"Country\", \"Continent\")\nglobalPop <- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %>%\n  mutate_if(is.character, as.factor) %>%  \n  mutate(Year = as.integer(Year))"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex03/Hands-On_Ex3b.html#animated-data-visualisation",
    "href": "Hands-On_Ex/Hands-On_Ex03/Hands-On_Ex3b.html#animated-data-visualisation",
    "title": "4 Animated Statistical Graph with R",
    "section": "4.3 Animated data visualisation",
    "text": "4.3 Animated data visualisation\nThe basic ggplot2 functions are used to create the static bubble plot.\n\n\nShow the code\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\n\n\n\n\n\n\nThe graph looks awful…\n\n\n\nThis is because all data points for all featured countries across all years were plotted on a single chart. Read on to see the magic of animated charts 😜.\n\n\n\n4.3.1 Working with gganimate package\ngganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\nBuilding the animated bubble plot\nIn the following chart:\n\ntransition_time() is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\n\nShow the code\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes(y = 'linear')          \n\n\n\n\n\n\n\n4.3.2 Working with plotly package\nIn Plotly R package, both ggplotly() and plot_ly() support key frame animations through the frame argument/aesthetic. They also support an ids argument/aesthetic to ensure smooth transitions between objects with the same id (which helps facilitate object constancy).\nIn the following graph, ggplotly() is used to convert the ggplot2 graph into an animated object.\nggplotly(gg)\n\n\nShow the code\ngg <- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') +\n  theme(legend.position='none')\n\nggplotly(gg)\n\n\n\n\n\n\nIn this next graph, we will use plot_ly() function to create the animated bubble plot.\n\n\nShow the code\nbp <- globalPop %>%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent, \n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers') %>%\n  layout(xaxis=list(title='% Old',\n                showgrid=FALSE,\n                zeroline=FALSE,\n                showticklabels=FALSE),\n         yaxis=list(title='% Young'))\nbp"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex03/Hands-On_Ex3b.html#reference",
    "href": "Hands-On_Ex/Hands-On_Ex03/Hands-On_Ex3b.html#reference",
    "title": "4 Animated Statistical Graph with R",
    "section": "4.4 Reference",
    "text": "4.4 Reference\n\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels\nHow to change the yaxis linecolor in the horizontal bar? - Plotly R, MATLAB, Julia, Net / Plotly R - Plotly Community Forum: This helps to resolve the black y-axis in the last bubble plot. The interesting finding is that we have to set the x-axis’s zeroline argument to FALSE to resolve the issue 😅.\n\n\n\\(**That's\\) \\(all\\) \\(folks!**\\)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4a.html",
    "href": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4a.html",
    "title": "5 Visual Statistical Analysis",
    "section": "",
    "text": "(First Published: May 4, 2023)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4a.html#learning-outcome",
    "href": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4a.html#learning-outcome",
    "title": "5 Visual Statistical Analysis",
    "section": "5.1 Learning Outcome",
    "text": "5.1 Learning Outcome\nWe will learn to create visual graphics with rich statistical information, visualise model diagnostics, and model parameters."
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4a.html#getting-started",
    "href": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4a.html#getting-started",
    "title": "5 Visual Statistical Analysis",
    "section": "5.2 Getting Started",
    "text": "5.2 Getting Started\n\n5.2.1 Install and load the required r libraries\nInstall and load the the required R packages. The name and function of the new package that will be used for this exercise are as follow:\n\nggstatsplot: offers various types of statistical plots and functions for statistical tests such as t-tests, ANOVA, correlation tests, and regression analysis\nperformance: offers functions for computing model evaluation metrics for model evaluation and comparison\nparameters: provides for managing complex experiments with many parameters and for automating parameter tuning in machine learning workflows\nsee: provides a host of functions and tools to produce a range of publication-ready visualizations for model parameters, predictions, and performance diagnostics\n\n\n\nShow the code\npacman::p_load(tidyverse,readxl, ggstatsplot, performance, parameters, see)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4a.html#visual-statistical-analysis-with-ggstatsplot-package",
    "href": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4a.html#visual-statistical-analysis-with-ggstatsplot-package",
    "title": "5 Visual Statistical Analysis",
    "section": "5.3 Visual Statistical Analysis with ggstatsplot package",
    "text": "5.3 Visual Statistical Analysis with ggstatsplot package\nggstatsplot is an extension of ggplot2 package for creating graphics enriched with statistical test details. It:\n\nProvides alternative statistical inference methods by default.\nFollows the best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the APA gold standard for statistical reporting. For example, here are the results from a t-test:\n\n\n\n5.3.1 Import the data\nWe will be using the same exam scores data-set that was featured in my Hands-On Exercise for Week 1.\n\n\nShow the code\nexam <- read_csv('data/Exam_data.csv', show_col_types = FALSE )\n\n\n\n\n5.3.2 One-sample Mean Test\nWe use gghistostats() to to build an visual of one-sample test on English scores.\nIn the following case:\n\ntype = \"bayes\": specifies the type of statistical test to perform on the data to generate the interval estimate. In this case, it is a Bayesian analysis, which provides a posterior distribution of plausible values based on prior knowledge and observed data.\ntest.value = 60: specifies the value for the null hypothesis that will be used to calculate the probability of the observed data. In this case, it is 60, which assumes that the average English score is 60.\n\n\n\nShow the code\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\nUnpacking the Bayes Factor\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThe Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as:\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\nHow to interpret Bayes Factor\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013: \n\n\n5.3.3 Two-sample Mean Test\nNext, we use ggbetweenstats() to build a visual for two-sample mean test of Maths scores by gender. This generates a combination of box and violin plots along with jittered data points for between-subjects designs with statistical details included in the plot as a subtitle.\nIn the following case:\n\ntype = \"np\": specifies the type of test to be used to compare the groups, in this case, a non-parametric test (Wilcoxon-Mann-Whitney test).\nmessages = FALSE: specifies whether or not to display informative messages about the statistical test being performed.\n\n\n\nShow the code\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n5.3.4 One-way ANOVA Test\nWe can also use ggbetweenstats() to build a visual for One-way ANOVA test on English score by race.\nIn the following case:\n\ntype = \"p\": specifies the type of test to be used to compare the groups, in this case, a parametric test (one-way ANOVA).\nmean.ci = TRUE: specifies whether or not to display confidence intervals for the group means.\npairwise.comparisons = TRUE: specifies whether or not to display pairwise comparisons between the groups.\npairwise.display = \"s\": specifies the format of the pairwise comparison display, in this case, “s” for compact letter display.\np.adjust.method = \"fdr\": specifies the method used for p-value adjustment for multiple comparisons, in this case, false discovery rate (FDR) correction.\n\n\n\nShow the code\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nSummary of tests with ggbetweenstats\n  \n\n\n5.3.5 Significant Test of Correlation\nWe can use ggscatterstats() to build a visual for Significant Test of Correlation between Maths scores and English scores. This creates a scatter plot with overlaid regression lines between the variables “MATHS” and “ENGLISH” in the “exam” dataset.\nIn the following case:\n\nmarginal = TRUE: specifies whether or not to display marginal histograms or density plots along the axes of the scatter plot. In this case, marginal plots are not displayed.\n\n\n\nShow the code\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = TRUE,\n  )\n\n\n\n\n\n\n\n5.3.5 Significant Test of Association (Dependence)\nFirst, we bin the Maths scores into a 4-class variable using cut() function.\n\n\nShow the code\nexam1 <- exam %>% \n  mutate(MATHS_bins = cut(MATHS, \n               breaks = c(0,60,75,85,100))\n  )\n\n\nWe use ggbarstats() to build a visual for Significant Test of Association between the categorised Maths scores and gender.\n\n\nShow the code\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4a.html#visualise-models",
    "href": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4a.html#visualise-models",
    "title": "5 Visual Statistical Analysis",
    "section": "5.4 Visualise Models",
    "text": "5.4 Visualise Models\nIn this section, we will learn how to visualise model diagnostic and model parameters.\n\n5.4.1 Import the data\nToyota Corolla case study will be used and the datat-set is imported. We will build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables.\n\n\nShow the code\ncar_resale <- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   <dbl> <chr>    <dbl>     <dbl>     <dbl>    <dbl>  <dbl>         <dbl>  <dbl>\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period <dbl>, HP_Bin <chr>, CC_bin <chr>,\n#   Doors <dbl>, Gears <dbl>, Cylinders <dbl>, Fuel_Type <chr>, Color <chr>,\n#   Met_Color <dbl>, Automatic <dbl>, Mfr_Guarantee <dbl>,\n#   BOVAG_Guarantee <dbl>, ABS <dbl>, Airbag_1 <dbl>, Airbag_2 <dbl>,\n#   Airco <dbl>, Automatic_airco <dbl>, Boardcomputer <dbl>, CD_Player <dbl>,\n#   Central_Lock <dbl>, Powered_Windows <dbl>, Power_Steering <dbl>, …\n\n\n\n\n5.4.2 Create a Multi-variate Linear Regression Model\nWe use lm() function of R Base Stats to calibrate a multi-variate linear regression model.\n\n\nShow the code\nmodel <- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\n5.4.3 Model Diagnostic: Check for Multicolinearity\nWe use check_collinearity() of performance package to conduct the test.\n\n\nShow the code\ncheck_collinearity(model)\n\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\nShow the code\nplot(check_collinearity(model))\n\n\n\n\n\n\n\n5.4.4 Model Diagnostic: Check Normality Assumption\nThere is the check_normality() function to conduct the test.\n\n\nShow the code\nmodel1 <- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\ncheck_n <- check_normality(model1)\n\nplot(check_n)\n\n\n\n\n\n\n\n5.4.5 Model Diagnostic: Check model for homogeneity of variances\nWe can use the check_heteroscedasticity() to do this check.\n\n\nShow the code\ncheck_h <- check_heteroscedasticity(model1)\n\nplot(check_h)\n\n\n\n\n\n\n\n5.4.6 Model Diagnostic: Complete Check\nThank goodness! There’s also a check_model()function to conduct the diagnostic tests discussed above.\n\n\nShow the code\ncheck_model(model1)\n\n\n\n\n\n\n\n5.4.7 Visualise Regression Parameters\nWe can use plot() function of see package and parameters() of parameters package to visualise the parameters of a regression model.\n\n\nShow the code\nplot(parameters(model1))\n\n\n\n\n\nAlternatively, we can use ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\n\nShow the code\nggcoefstats(model1, \n            output = \"plot\")\n\n\n\n\n\n\n\\(**That's\\) \\(all\\) \\(folks!**\\)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4b.html",
    "href": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4b.html",
    "title": "6 Visualise Uncertainty",
    "section": "",
    "text": "(First Published: 4-May-2023)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4b.html#learning-outcome",
    "href": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4b.html#learning-outcome",
    "title": "6 Visualise Uncertainty",
    "section": "6.1 Learning Outcome",
    "text": "6.1 Learning Outcome\nA point estimate, such as mean, is a single numerical value that is used to estimate an unknown population parameter. On the other hand, a range estimate is a range of values that is used to estimate an unknown population parameter. A range estimate is useful when a single point estimate is not precise enough, or when we want to communicate the level of uncertainty surrounding the point estimate.\nIn this exercise, we will explore approaches to visualise the uncertainty of point estimates."
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4b.html#getting-started",
    "href": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4b.html#getting-started",
    "title": "6 Visualise Uncertainty",
    "section": "6.2 Getting Started",
    "text": "6.2 Getting Started\n\n6.2.1 Install and load the required r libraries\nInstall and load the the required R packages. The name and function of the new package that will be used for this exercise is as follow:\n\nggdist: provides a range of functions for creating visualizations of probability distributions\nknitr: create high-quality, fully reproducible documents that integrate code, text, and graphics\n\n\n\nShow the code\npacman::p_load(tidyverse, plotly, crosstalk, DT, gganimate, ggdist, knitr)\n\n\n\n\n6.2.2 Import the data\nWe will be using the same exam scores data-set that was featured in my Hands-On Exercise for Week 1.\n\n\nShow the code\nexam <- read_csv('data/Exam_data.csv', show_col_types = FALSE )"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4b.html#visualise-the-uncertainty-of-point-estimates-with-ggplot2-package",
    "href": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4b.html#visualise-the-uncertainty-of-point-estimates-with-ggplot2-package",
    "title": "6 Visualise Uncertainty",
    "section": "6.3 Visualise the uncertainty of point estimates with ggplot2 package",
    "text": "6.3 Visualise the uncertainty of point estimates with ggplot2 package\nFirst, we perform with following on the exam scores data-set:\n\ngroup the observations by RACE,\ncompute the count of observations, mean, standard deviation and standard error of Maths scores by RACE, and\nassign the output as a tibble data table called `my_sum\nprint the tibble data using kable() function from knitr\n\n\n\nShow the code\nmy_sum <- exam %>%\n  group_by(RACE) %>%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %>%\n  mutate(se=sd/sqrt(n-1))\n\nkable(head(my_sum), format = 'html') \n\n\n\n\n \n  \n    RACE \n    n \n    mean \n    sd \n    se \n  \n \n\n  \n    Chinese \n    193 \n    76.50777 \n    15.69040 \n    1.132357 \n  \n  \n    Indian \n    12 \n    60.66667 \n    23.35237 \n    7.041005 \n  \n  \n    Malay \n    108 \n    57.44444 \n    21.13478 \n    2.043177 \n  \n  \n    Others \n    9 \n    69.66667 \n    10.72381 \n    3.791438 \n  \n\n\n\n\n\nWe can use the geom_errorbar() function to reveal the standard error of mean maths score by race in the following chart.\n\n\nShow the code\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard Error of the Mean Math Scores by Race\")\n\n\n\n\n\n\n\n\n\n\n\nWe plotted this before...\n\n\n\nCheck out this plot which we did in an earlier exercise.\n\n\nWe can also use the geom_errorbar() function to reveal the 95% Confidence Interval of the mean maths score by race in the following chart.\n\n# Calculate the lower and upper bound for confidence intervals\nmy_sum2 <- my_sum %>% \n  mutate(lower_ci = mean - qt(0.975, n-1)*se,\n         upper_ci = mean + qt(0.975, n-1)*se)\n\n# Create point estimate plot with error bars\nggplot(my_sum2) +\n  geom_errorbar(\n    aes(x=reorder(RACE,-mean), \n        ymin=lower_ci, \n        ymax=upper_ci), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(title=\"95% Confidence Interval of the Mean Math Scores by Race\",\n       x = \"Race\",\n       y = \"Math Score\")\n\n\n\n\n\n6.3.1 Visualise the uncertainty of point estimates with interactive error bars\nThe following interactive error bar plot shows the 99% Confidence Interval of mean maths score by race.\n( 🖱️Click on the average score (in red) for the cross-filtering to work)\n\n\nShow the code\n# Prepare the summary table with the relevant stats\nmy_sum3 <- exam %>%\n  group_by(RACE) %>%\n  summarise(\n    'No. of pupils'=n(),\n    'Avg Scores'=mean(MATHS),\n    'Std Dev'=sd(MATHS),\n    'Std Error' = sd(MATHS)/sqrt(n()-1)\n    ) \n\n# Use highlight_key() to add a unique key to the data frame my_sum3 so that it can be linked to interactive plots later\nd <- highlight_key(my_sum3)\n\n# Prepare the error bar plot\np <- ggplot(d) +\n  geom_errorbar(\n    aes(x=reorder(RACE,-`Avg Scores`), \n        ymin=`Avg Scores` - qt(0.995, `No. of pupils`-1)*`Std Error`, \n        ymax=`Avg Scores` + qt(0.995, `No. of pupils`-1)*`Std Error`), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=`Avg Scores`,\n            text = paste(\"Race:\", `RACE`, \n                                  \"<br>N:\", `No. of pupils`,\n                                  \"<br>Avg. Scores:\", round(`Avg Scores`, digits = 2),\n                                  \"<br>95% CI:[\", \n                                  round((`Avg Scores` - qt(0.995, `No. of pupils`-1)*`Std Error`), digits = 2), \",\",\n                                  round((`Avg Scores` + qt(0.995, `No. of pupils`-1)*`Std Error`), digits = 2),\"]\")), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(title=\"99% Confidence Interval of the Mean Math Scores by Race\",\n       x = \"Race\",\n       y = \"Math Score\")\n\n# Convert ggplot to an interactive plotly plot using the ggplotly(), \"plotly click\" specifies that highlight should be based on click\ngg <- highlight(ggplotly(p),on =        \n                \"plotly_click\")\n\n# Create a Bootstrap grid of two columns to house the 2 plots in the ratio of 5:7\nbscols(gg,datatable(d,options = list(dom='t')),widths = c(5,7))"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4b.html#visualising-uncertainty-using-ggdist-package",
    "href": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4b.html#visualising-uncertainty-using-ggdist-package",
    "title": "6 Visualise Uncertainty",
    "section": "6.4 Visualising Uncertainty using ggdist package",
    "text": "6.4 Visualising Uncertainty using ggdist package\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty. It is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\nWe use the stat_pointinterval() of ggdist to build a visual for displaying distribution of maths scores by race.\n\n\nShow the code\nexam %>%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +   #<<\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\") +\n  theme_minimal()\n\n\n\n\n\nThis stat_pointinterval() function comes with many arguments. The following plot creates a plot that displays the median math score for each race group, along with an interval estimate for each group. This can help visualize the differences in math scores across different racial groups and also the variability within each group.\n\n\nShow the code\nexam %>%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  point_interval = \"median_qi\"\n  ) +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\nWe can use the stat_gradientinterval() function of ggdist to build a visual for displaying distribution of maths scores by race.\n\n\nShow the code\nexam %>%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4b.html#visualise-uncertainty-with-hypothetical-outcome-plots-hops",
    "href": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4b.html#visualise-uncertainty-with-hypothetical-outcome-plots-hops",
    "title": "6 Visualise Uncertainty",
    "section": "6.5 Visualise Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "6.5 Visualise Uncertainty with Hypothetical Outcome Plots (HOPs)\nThe ungeviz package is meant to provide helpful add-on functionality for ggplot2 to visualize uncertainty. The package is particularly focused on hypothetical outcome plots (HOPs) and provides bootstrapping and sampling functionality that integrates well with the ggplot2 API.\nStep 1: Install the ungeviz package\n\n\nShow the code\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe installation should only be carried out once.\n\n\nStep 2: Launch the application in R\n\n\nShow the code\nlibrary(ungeviz)\n\n\n\n\nShow the code\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe sampler() function generates sampling and bootstrapping exam scores repeatedly and these scores are used as input data in ggplot2 layer. This helps to create the hypothetical outcome plot.\n\n\n\n\\(**That's\\) \\(all\\) \\(folks!**\\)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4c.html",
    "href": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4c.html",
    "title": "7 Funnel Plots for Fair Comparison",
    "section": "",
    "text": "(First Published: May 4, 2023)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4c.html#learning-outcome",
    "href": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4c.html#learning-outcome",
    "title": "7 Funnel Plots for Fair Comparison",
    "section": "7.1 Learning Outcome",
    "text": "7.1 Learning Outcome\nFunnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities.\nIn this hands-on exercise, we will learn to design and produce static and interactive funnel plots."
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4c.html#getting-started",
    "href": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4c.html#getting-started",
    "title": "7 Funnel Plots for Fair Comparison",
    "section": "7.2 Getting Started",
    "text": "7.2 Getting Started\n\n7.2.1 Install and load the required r libraries\nInstall and load the the required R packages. The name and function of the new packages that will be used for this exercise are as follow:\n\nFunnelPlotR for creating funnel plot\nkableExtra for additional functionality to format kable() tables\n\n\n\nShow the code\npacman::p_load(tidyverse, plotly, knitr, FunnelPlotR, kableExtra )\n\n\n\n\n7.2.2 Import the data\nWe will be using the COVID-19_DKI_Jakarta data-set. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nWe import the data into R and save it into a tibble data frame object called covid19.\n\n\nShow the code\ncovid19 <- read_csv(\"data/COVID-19_DKI_Jakarta.csv\", show_col_types = FALSE) %>%\n  mutate_if(is.character, as.factor)\n\nkable(head(covid19), format = 'html', caption = \"Table 1 First Records from the Covid-19 dataset\")%>%\n  kable_styling(\"striped\")\n\n\n\n\nTable 1 First Records from the Covid-19 dataset\n \n  \n    Sub-district ID \n    City \n    District \n    Sub-district \n    Positive \n    Recovered \n    Death \n  \n \n\n  \n    3172051003 \n    JAKARTA UTARA \n    PADEMANGAN \n    ANCOL \n    1776 \n    1691 \n    26 \n  \n  \n    3173041007 \n    JAKARTA BARAT \n    TAMBORA \n    ANGKE \n    1783 \n    1720 \n    29 \n  \n  \n    3175041005 \n    JAKARTA TIMUR \n    KRAMAT JATI \n    BALE KAMBANG \n    2049 \n    1964 \n    31 \n  \n  \n    3175031003 \n    JAKARTA TIMUR \n    JATINEGARA \n    BALI MESTER \n    827 \n    797 \n    13 \n  \n  \n    3175101006 \n    JAKARTA TIMUR \n    CIPAYUNG \n    BAMBU APUS \n    2866 \n    2792 \n    27 \n  \n  \n    3174031002 \n    JAKARTA SELATAN \n    MAMPANG PRAPATAN \n    BANGKA \n    1828 \n    1757 \n    26"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4c.html#funnelplotr-methods",
    "href": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4c.html#funnelplotr-methods",
    "title": "7 Funnel Plots for Fair Comparison",
    "section": "7.3 FunnelPlotR methods",
    "text": "7.3 FunnelPlotR methods\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: label outliers (true or false).\nPoisson_limits: add Poisson limits to the plot.\nOD_adjust: add overdispersed limits to the plot.\nxrange and yrange: specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n\n\n\n\n\nHow do I interpret a funnel plot?\n\n\n\nCheck out this video which explains the elements of the funnel plot and how it is constructed.\n\n\n\n7.3.1 FunnelPlotR methods: The Basic Plot\nWe use the funnel_plot() function to create a basic plot. Things to note:\n\ngroup argument is different from that in the scatterplot. Here, it specifics the level of the points to be plotted i.e. Sub-district, District or City. If City is chosen, there will only be six data points.\nBy default, data_typeargument is “SR”.\nlimit: the accepted plot limit values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\nShow the code\nfunnel_plot(\n  numerator = covid19$Positive,\n  denominator = covid19$Death,\n  group = covid19$`Sub-district`\n)\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n7.3.2 FunnelPlotR methods: Makeover Part 1\nWe updated the arguments used in the funnel_plot() function to create the following plot:\n\ndata_type: A character string specifying the type of data to be plotted. In this case, it is set to “PR”, which stands for proportion or percentage, indicating that the data in the numerator and denominator arguments are in the form of proportions or percentages, and not absolute counts.\nx_range: A numeric vector of length two specifying the range of the x-axis of the plot. Here, it is set to c(0, 6500), which means the x-axis ranges from 0 to 6500.\ny_range: A numeric vector of length two specifying the range of the y-axis of the plot. Here, it is set to c(0, 0.05), which means the y-axis ranges from 0 to 0.05.\n\n\n\nShow the code\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",     #<<\n  x_range = c(0, 6500),  #<<\n  y_range = c(0, 0.05)   #<<\n)\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n7.3.3 FunnelPlotR methods: Makeover Part 2\nFurther updates to the relevant arguments of the funnel_plot() function are:\n\nlabel: A logical value indicating whether or not to display the group labels on the plot. Here, it is set to NA, which means that no labels will be displayed.\ntitle: A character string specifying the title of the plot. Here, it is set to “COVID-19 Fatality Rate by Total Number of COVID-19 Positive Cases”.\nx_label: A character string specifying the label for the x-axis of the plot. Here, it is set to “COVID-19 Positive Cases”.\ny_label: A character string specifying the label for the y-axis of the plot. Here, it is set to “Fatality Rate”.\n\n\n\nShow the code\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",   \n  x_range = c(0, 6500),  \n  y_range = c(0, 0.05),\n  label = NA,\n  title = \"COVID-19 Fatality Rate by Total Number of COVID-19 Positive Cases\", #<<           \n  x_label = \"COVID-19 Positive Cases\", #<<\n  y_label = \"Fatality Rate\"  #<<\n)\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion."
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4c.html#funnel-plot-for-fair-visual-comparison-using-ggplot2-package",
    "href": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4c.html#funnel-plot-for-fair-visual-comparison-using-ggplot2-package",
    "title": "7 Funnel Plots for Fair Comparison",
    "section": "7.4 Funnel Plot for Fair Visual Comparison using ggplot2 package",
    "text": "7.4 Funnel Plot for Fair Visual Comparison using ggplot2 package\nIn this section, we will learn to build funnel plots step-by-step by using ggplot2. This will enhance our working experience of ggplot2 to customise a speciallised data visualisation like funnel plot.\n\n7.4.1 Derive the basic statistics\nTo plot the funnel plot from scratch, we need to derive cumulative death rate (or fatality rate) and standard error of cumulative death rate.\n\n\n\nStandard Error for Sample Proportion\n\n\n\n\nShow the code\ndf <- covid19 %>%\n  mutate(rate = Death / Positive) %>%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %>%\n  filter(rate > 0)\n\n\nNext, we derive the weighted mean of the values. In this case, we use the weighted.mean() function to find the weighted mean of the rate values.\n\n\nShow the code\nfit.mean <- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n\n7.4.2 Calculate lower and upper limits for 95% and 99.9% Confidence Interval\nWe will then compute the lower and upper limits for 95% and 99.9% confidence interval.\n\n\nShow the code\nnumber.seq <- seq(1, max(df$Positive), 1)\nnumber.ll95 <- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 <- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 <- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 <- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \n\ndfCI <- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\nkable(head(dfCI), format = 'html', caption = \"Table 2 First Records of CI Intervals and Fit.Mean Value\")%>%\n  kable_styling(\"striped\")\n\n\n\n\nTable 2 First Records of CI Intervals and Fit.Mean Value\n \n  \n    number.ll95 \n    number.ul95 \n    number.ll999 \n    number.ul999 \n    number.seq \n    fit.mean \n  \n \n\n  \n    -0.2230353 \n    0.2529745 \n    -0.3845386 \n    0.4144778 \n    1 \n    0.0149696 \n  \n  \n    -0.1533253 \n    0.1832645 \n    -0.2675254 \n    0.2974645 \n    2 \n    0.0149696 \n  \n  \n    -0.1224426 \n    0.1523818 \n    -0.2156866 \n    0.2456257 \n    3 \n    0.0149696 \n  \n  \n    -0.1040328 \n    0.1339720 \n    -0.1847845 \n    0.2147237 \n    4 \n    0.0149696 \n  \n  \n    -0.0914694 \n    0.1214086 \n    -0.1636959 \n    0.1936351 \n    5 \n    0.0149696 \n  \n  \n    -0.0821955 \n    0.1121347 \n    -0.1481289 \n    0.1780681 \n    6 \n    0.0149696 \n  \n\n\n\n\n\n\n\n7.4.3 Create a static funnel plot\nWe can use ggplot2 functions to plot a static funnel plot\n\n\nShow the code\np <- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            linewidth = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            linewidth = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            linewidth = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            linewidth = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             linewidth = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Fatality Rate by Number of COVID-19 Cases\") +\n  xlab(\"Number of COVID-19 Cases\") + \n  ylab(\"Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\n\n7.4.4 Create an Interactive Funnel Plot\nThe funnel plot created using ggplot2 functions above can be made interactive with ggplotly() of plotly package.\n\n\nShow the code\nfp_ggplotly <- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4c.html#references",
    "href": "Hands-On_Ex/Hands-On_Ex04/Hands-On_Ex4c.html#references",
    "title": "7 Funnel Plots for Fair Comparison",
    "section": "7.5 References",
    "text": "7.5 References\n\nfunnelPlotR package.\nFunnel Plots for Indirectly-standardised ratios.\nChanging funnel plot options\nggplot2 package.\n\n\n\\(**That's\\) \\(all\\) \\(folks!**\\)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex05/Hands-On_Ex5a.html",
    "href": "Hands-On_Ex/Hands-On_Ex05/Hands-On_Ex5a.html",
    "title": "8 Visualise Distribution",
    "section": "",
    "text": "(First Published: May 12, 2023)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex05/Hands-On_Ex5a.html#learning-outcome",
    "href": "Hands-On_Ex/Hands-On_Ex05/Hands-On_Ex5a.html#learning-outcome",
    "title": "8 Visualise Distribution",
    "section": "8.1 Learning Outcome",
    "text": "8.1 Learning Outcome\nWe will learn 2 fairly new techniques to visual distribution, namely:\n\nridgeline plot\nraincloud plot"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex05/Hands-On_Ex5a.html#getting-started",
    "href": "Hands-On_Ex/Hands-On_Ex05/Hands-On_Ex5a.html#getting-started",
    "title": "8 Visualise Distribution",
    "section": "8.2 Getting Started",
    "text": "8.2 Getting Started\n\n8.2.1 Install and load the required r libraries\nInstall and load the the required R packages. The name and function of the new packages that will be used for this exercise are as follow:\n\nggridges : a ggplot2 extension specially designed for plotting ridgeline plots\ncolorspace : for working with and manipulating colors\n\n\n\nShow the code\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse,plotly)\n\n\n\n\n8.2.2 Import the data\nWe will be using the same exam scores data-set that was featured in my Hands-On Exercise for Week 1.\n\n\nShow the code\nexam <- read_csv(\"data/Exam_data.csv\", show_col_types = FALSE)\n\n\n8.3 Visualise Distribution with Ridegeline plots\nRidgeline plot (sometimes called Joyplot) is a data visualisation technique for revealing the distribution of a numeric value for several groups. Distribution can be represented using histograms or density plots, all aligned to the same horizontal scale and presented with a slight overlap.\nThe figure below is a ridgelines plot showing the distribution of English score by class.\n\n\n\n\n\n\n\nNote\n\n\n\n\nRidgeline plots can be used when the number of groups to be represented is medium to high, and where a classic window separation would take to much space. Indeed, the fact that groups overlap each other allows to use space more efficiently. If we have fewer than 5 groups, using other distribution plots is probably better.\nIt works well especially when there is a clear pattern in the result, like if there is an obvious ranking in groups. In other cases, the groups will tend to overlap each other, leading to a messy plot not providing any insight.\n\n\n\n8.3.1 Plotting ridgeline graph: ggridges package\nThere are several ways to plot ridgeline plot with R. In this section, we will learn how to plot ridgeline plot by using ggridges package.\nggridges package provides two main geoms to plot gridgeline plots, they are: geom_ridgeline() and geom_density_ridges(). The former takes height values directly to draw the ridgelines, and the latter first estimates data densities and then draws those using density curves.\nThe ridgeline plot below is plotted by using geom_density_ridges()\n\n\nShow the code\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(\n    name = NULL, \n    expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n8.3.2 Vary fill colors along the x axis\nSometimes we would like to have the area under a ridgeline not filled with a single solid color but rather with colors that vary with the x axis. This effect can be achieved by using either geom_ridgeline_gradient() or geom_density_ridges_gradient(). Both geoms work just like geom_ridgeline() and geom_density_ridges(), except that they allow for varying fill colors. However, they do not allow for alpha transparency in the fill. For technical reasons, we can have changing fill colors or transparency but not both.\n\n\nShow the code\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = after_stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(\n    name = NULL, \n    expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n8.3.3 Map the probabilities directly onto colour\nBeside providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\nThe figure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score.\n\n\nShow the code\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\nImportant!\n\n\n\nThe argument calc_ecdf = TRUE must be included in the stat_density_ridges() function.\n\n\n\n\n8.3.4 Ridgeline plots with quantile lines\nBy using geom_density_ridges_gradient(), we can colour the ridgeline plot by quantile, via the calculated stat(quantile) aesthetic as shown in the figure below.\n\n\nShow the code\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\n\nShow the code\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex05/Hands-On_Ex5a.html#visualise-distribution-with-raincloud-plot",
    "href": "Hands-On_Ex/Hands-On_Ex05/Hands-On_Ex5a.html#visualise-distribution-with-raincloud-plot",
    "title": "8 Visualise Distribution",
    "section": "8.4 Visualise Distribution with Raincloud Plot",
    "text": "8.4 Visualise Distribution with Raincloud Plot\nRaincloud Plot is a data visualisation technique that produces a density and a dot plot symmetrically cupped together along a common pane. It gets the name because the density plot is in the shape of a “raincloud” while the dots represent raindrops 🌧️. The raincloud (half-density) plot enhances the traditional box-plot by highlighting multiple modalities (an indicator that groups may exist). The boxplot does not show where densities are clustered, but the raincloud plot does!\nIn this section, we will learn how to create a raincloud plot to visualise the distribution of English scores by race. It will be created by using functions provided by ggdist and ggplot2 packages.\n\n8.4.1 Plotting a Half Eye graph\nFirst, we will plot a Half-Eye graph by using stat_halfeye() of ggdist package.\nThis produces a Half Eye visualization, which is contains a half-density and a slab-interval. We remove the slab interval by setting .width = 0 and point_colour = NA.\n\n\nShow the code\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\n\n\n\n8.4.2 Adding the boxplot with geom_boxplot()\nNext, we will add the second geometry layer using geom_boxplot() of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\n\nShow the code\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  # Add'l codes from the previous plot\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\n\n8.4.3 Adding the Dot Plots with stat_dots()\nNext, we will add the third geometry layer using stat_dots() of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. We select side = “left” to indicate we want it on the left-hand side.\n\n\nShow the code\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  # Add'l codes from the previous plot\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n\n8.4.4 Finishing touch\nLastly, coord_flip() of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. At the same time, theme_economist() of ggthemes package is used to give the raincloud chart a professional publishing standard look.\n\n\nShow the code\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  # Add'l codes from the previous plot\n  coord_flip() +\n  theme_economist() +\n  # Add geom_text layer for displaying median values\n  stat_summary(fun = median, geom = \"text\", aes(label = round(..y.., 1)),\n               position = position_nudge(x = 0.15), vjust = -0.5) +\n  # Add geom_text layer for displaying mean dot in red\n  stat_summary(fun = mean, geom = \"point\", shape = 16, size = 3, color = \"red\",\n               position = position_nudge(x = 0.0)) +\n    stat_summary(fun = mean, geom = \"text\", aes(label = round(..y.., 0)),\n               position = position_nudge(x = 0.15), vjust = 2.5, color = \"red\") \n\n\n\n\n\n\n\\(**That's\\) \\(all\\) \\(folks!**\\)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex05/Hands-On_Ex5b.html",
    "href": "Hands-On_Ex/Hands-On_Ex05/Hands-On_Ex5b.html",
    "title": "9 Visualise Network Data",
    "section": "",
    "text": "(First Published: May 12, 2023)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex05/Hands-On_Ex5b.html#learning-outcome",
    "href": "Hands-On_Ex/Hands-On_Ex05/Hands-On_Ex5b.html#learning-outcome",
    "title": "9 Visualise Network Data",
    "section": "9.1 Learning Outcome",
    "text": "9.1 Learning Outcome\nBy the end of this hands-on exercise, we will be able to:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package."
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex05/Hands-On_Ex5b.html#getting-started",
    "href": "Hands-On_Ex/Hands-On_Ex05/Hands-On_Ex5b.html#getting-started",
    "title": "9 Visualise Network Data",
    "section": "9.2 Getting Started",
    "text": "9.2 Getting Started\n\n9.2.1 Install and load the required r libraries\nInstall and load the the required R packages. The name and function of the new packages that will be used for this exercise are as follow:\n\ngraph: The ‘graph’ package is used for creating, manipulating, and analyzing graphs and networks\ntidygraph: Builds on top of the graph package and extends it with the principles of the ‘tidyverse’. It allows for a tidy data approach to working with graph data by providing a grammar of graph manipulation.\nggraph: For visualizing graphs and networks. It provides a flexible and intuitive grammar of graphics interface for creating customized and aesthetically pleasing network visualizations.\nvisNetwork: For creating interactive network plots with features like zooming, panning, tooltips, and filtering.\nlubridate: Provides convenient functions to parse, manipulate, and work with dates and times.\nclock: A modern alternative to ‘lubridate’ for handling date and time data.\ngraphlayouts: Provides various layout algorithms for visualizing graphs and networks.\n\n\n\nShow the code\npacman::p_load(igraph, tidygraph, ggraph, visNetwork, lubridate, clock,               tidyverse, graphlayouts)\n\n\n\n\n9.2.2 Import the data\nThe data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets:\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees.\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees\n\n\n\nShow the code\nGAStech_nodes <- read_csv(\"data/GAStech_email_node.csv\", show_col_types = FALSE)\nGAStech_edges <- read_csv(\"data/GAStech_email_edge-v2.csv\", show_col_types = FALSE)\n\n\nReview the imported data\nWe will examine the structure of the data frame using glimpse() of dplyr.\n\n\nShow the code\nglimpse(GAStech_edges)\n\n\nRows: 9,063\nColumns: 8\n$ source      <dbl> 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      <dbl> 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    <chr> \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    <time> 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     <chr> \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject <chr> \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel <chr> \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel <chr> \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of date data type. Before we continue, it is important for us to change the data type of SentDate field back to “Date”” data type.\nCreate a new column for week day\nWe will use the dmy() and wday() functions of lubridate package to convert SentDate to ‘Date’ data type. To note the following:\n\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The abbr argument is set to FALSE to spell the day of the week in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\nShow the code\nGAStech_edges <- GAStech_edges %>%\n  mutate(SendDate = dmy(SentDate)) %>%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\nRemove unneeded records\nA close examination of GAStech_edges data.frame reveals that it consists of:\n\nnon-worked related emails\nweekends\nself-directed e-mails where the individuals send an email to themselves\nemails that were only sent once\n\nWe will wrangle the data to address these issues.\n\n\nShow the code\nGAStech_edges_aggregated <- GAStech_edges %>%\n  filter(MainSubject == \"Work related\") %>%\n  group_by(source, target, Weekday) %>%\n    summarise(Weight = n()) %>%\n  filter(source!=target) %>%\n  filter(Weight > 1) %>%\n  ungroup()"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex05/Hands-On_Ex5b.html#create-network-objects-using-tidygraph",
    "href": "Hands-On_Ex/Hands-On_Ex05/Hands-On_Ex5b.html#create-network-objects-using-tidygraph",
    "title": "9 Visualise Network Data",
    "section": "9.3 Create network objects using tidygraph",
    "text": "9.3 Create network objects using tidygraph\nWhile network data itself is not tidy, it can be envisioned as two tidy tables - one for node data and one for edge data. tidygraph provides a way to switch between the two tables and provides dplyr verbs for manipulating the data. Furthermore the package provides access to a lot of graph algorithms with return values that facilitate their use in a tidy workflow.\nThese two articles provide useful information on tidygraph:\n\nIntroducing tidygraph\ntidygraph 1.1 - A tidy hope\n\n\n9.3.1 The tbl_graph object\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor).\n\n\n\n\n9.3.2 The dplyr verbs in tidygraph\nThe activate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n In the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself.\n\n\n9.3.3 Using tbl_graph() to build tidygraph data model.\nWe will use tbl_graph() of tinygraph package to build an tidygraph’s network graph data.frame.\n\n\n\n\n\n\nTip\n\n\n\nBefore typing the codes, you are recommended to review to reference guide of tbl_graph()\n\n\n\n\nShow the code\nGAStech_graph <- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\nLet’s take a look at the output tidygraph’s graph object.\n\n\nShow the code\nGAStech_graph\n\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 54 × 4\n     id label               Department     Title                                \n  <dbl> <chr>               <chr>          <chr>                                \n1     1 Mat.Bramar          Administration Assistant to CEO                     \n2     2 Anda.Ribera         Administration Assistant to CFO                     \n3     3 Rachel.Pantanal     Administration Assistant to CIO                     \n4     4 Linda.Lagos         Administration Assistant to COO                     \n5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Manag…\n6     6 Carla.Forluniau     Administration Assistant to IT Group Manager        \n# ℹ 48 more rows\n#\n# A tibble: 1,372 × 4\n   from    to Weekday Weight\n  <int> <int> <ord>    <int>\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 1372 edges. The command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nChanging the active object\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\nFor example,\n\n\nShow the code\nGAStech_graph %>%\n  activate(edges) %>%\n  arrange(desc(Weight))\n\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# A tibble: 1,372 × 4\n   from    to Weekday  Weight\n  <int> <int> <ord>     <int>\n1    40    41 Saturday     13\n2    41    43 Monday       11\n3    35    31 Tuesday      10\n4    40    41 Monday       10\n5    40    43 Monday       10\n6    36    32 Sunday        9\n# ℹ 1,366 more rows\n#\n# A tibble: 54 × 4\n     id label           Department     Title           \n  <dbl> <chr>           <chr>          <chr>           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\n\n\n\n\n\n\nTip\n\n\n\nVisit the reference guide of activate() to find out more about the function."
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex05/Hands-On_Ex5b.html#plot-static-network-graphs-with-ggraph-package",
    "href": "Hands-On_Ex/Hands-On_Ex05/Hands-On_Ex5b.html#plot-static-network-graphs-with-ggraph-package",
    "title": "9 Visualise Network Data",
    "section": "9.4 Plot Static Network Graphs with ggraph package",
    "text": "9.4 Plot Static Network Graphs with ggraph package\nggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph’s network graph, they are:\n\nnodes,\nedges and\nlayouts.\n\nFor a comprehensive discussion of each of this aspect of graph, please refer to their respective vignettes provided.\n\n9.4.1 Plot a basic network graph\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before we get started, it is advisable to read their respective reference guide at least once.\n\n\nShow the code\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object.\n\n\n\n\n9.4.2 Change the default network graph theme\nWe can use theme_graph() to remove the x and y axes.\n\n\nShow the code\ng <- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots.\n\n\n\n\n\n9.4.3 Change the coloring of the plot\nThe theme_graph() funtion makes it easy to change the coloring of the plot\n\n\nShow the code\ng <- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\n\n9.4.4 Working with different graph layouts\nggraph supports many layouts for standard use. They are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl.\nThe figures below are supported by ggraph().  9.4.5 Fruchterman and Reingold layout\nWe can use the layout argument to the ggraph() function to specify the preferred layout.\n\n\nShow the code\ng <- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n9.4.5 Modify the network nodes\nWe can use the aes() function within the geom_node_point() function to assign the nodes with colors based on the department of the employees.\n\n\nShow the code\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\ngeom_node_point() is equivalent in functionality to geom_point() of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the code chunck above, colour and size are used.\n\n\n\n\n9.4.6 Modify the edges\nSimilarly, we can use the aes() function within the geom_edge_link() function to map the thickness of the edges with the Weight variable.\n\n\nShow the code\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\ngeom_edge_link() draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line."
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex05/Hands-On_Ex5b.html#creating-facet-graphs",
    "href": "Hands-On_Ex/Hands-On_Ex05/Hands-On_Ex5b.html#creating-facet-graphs",
    "title": "9 Visualise Network Data",
    "section": "9.5 Creating facet graphs",
    "text": "9.5 Creating facet graphs\nAnother very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, we will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\n9.5.1 Working with facet_edges()\nWe will use facet_edges() to generate graphs based on the day of the week.\n\n\nShow the code\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\nWe can change the position of the legend using the theme() layer.\n\n\nShow the code\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\n\nFurther tweaks to add frame and a subtitle border to each graph can be made via the th_background() function.\n\n\nShow the code\nset_graph_style() \n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n9.5.2 Working with facet_node()\nWe use the facet_node() function to generate departmental graphs in small multiples.\n\n\nShow the code\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex05/Hands-On_Ex5b.html#network-metric-analysis",
    "href": "Hands-On_Ex/Hands-On_Ex05/Hands-On_Ex5b.html#network-metric-analysis",
    "title": "9 Visualise Network Data",
    "section": "9.6 Network Metric Analysis",
    "text": "9.6 Network Metric Analysis\n\n9.6.1Compute Centrality Indices\nCentrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Go online to find out more!\nIn the graph below, we compute the Betweenness Centrality (a measure of how often the node serves as a bridge in the shortest path of other node pairs) of the nodes first and map it to the size of the nodes. Hence, the bigger the node, the higher its centrality score.\n\n\nShow the code\ng <- GAStech_graph %>%\n  mutate(betweenness_centrality = centrality_betweenness()) %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\nFrom ggraph v2.0 onwards, tidygraph algorithms such as centrality measures can be accessed directly in ggraph() calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\n\nShow the code\ng <- GAStech_graph %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\n\n9.6.2 Visualise Community\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph.\nIn the following graph, group_edge_betweenness() function is used to detect the communities.\n\n\nShow the code\ng <- GAStech_graph %>%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %>%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))  \n\ng + theme_graph()"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex05/Hands-On_Ex5b.html#build-interactive-network-graphs-with-visnetwork-package",
    "href": "Hands-On_Ex/Hands-On_Ex05/Hands-On_Ex5b.html#build-interactive-network-graphs-with-visnetwork-package",
    "title": "9 Visualise Network Data",
    "section": "9.7 Build interactive network graphs with visNetwork package",
    "text": "9.7 Build interactive network graphs with visNetwork package\nvisNetwork is a R package for network visualization, using vis.js javascript library.\nThe visNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an “id” column, and the edge list must have “from” and “to” columns.\nThe function also plots the labels for the nodes, using the names of the actors from the “label” column in the node list.\n\nThe resulting graph is fun to play around with.\n\nWe can move the nodes and the graph will use an algorithm to keep the nodes properly spaced.\nWe can also zoom in and out on the plot and move it around to re-center it.\n\n\n9.7.1 Data Preparation\nBefore we can plot the interactive network graph, we need to prepare the data by combining the 2 data sets and then group + filter the results.\n\n\nShow the code\nGAStech_edges_aggregated <- GAStech_edges %>%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %>%\n  rename(from = id) %>%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %>%\n  rename(to = id) %>%\n  filter(MainSubject == \"Work related\") %>%\n  group_by(from, to) %>%\n    summarise(weight = n()) %>%\n  filter(from!=to) %>%\n  filter(weight > 1) %>%\n  ungroup()\n\n\n\n\n9.7.2 Plot the basic interactive network graph\nIn the graph below, the Fruchterman and Reingold layout is used.\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nVisit Igraph to find out more about visIgraphLayout’s argument.\n\n\n\n\n9.7.3 Working with visual attributes - Nodes\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field. Hence, we will have to rename Department field to group.\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field.\n\n\nShow the code\n# Rename Department attribute to group\nGAStech_nodes <- GAStech_nodes %>%\n  rename(group = Department)\n\n# Re-gen the network group\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\n9.7.4 Working with visual attributes - Edges\nWe updated the following arguments in the visEdges() function to generate the graph below:\n\nThe arrows argument is used to define where to place the arrow.\nThe smooth argument is used to plot the edges using a smooth curve.\n\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nVisit Option to find out more about visEdges’s argument.\n\n\n\n\n9.7.5 Additional Interactivity\nNext, we updated the following arguments in the visOptions() function to generate the graph below:\n\nThe highlightNearest argument to highlight nearest when clicking a node.\nThe nodesIdSelection argument adds an id node selection creating an HTML select element.\n\n\n\nShow the code\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nVisit Option to find out more about visOption’s argument.\n\n\n\n\\(**That's\\) \\(all\\) \\(folks!**\\)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6a.html",
    "href": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6a.html",
    "title": "10 Ternary Plot to display composition of 3 variables",
    "section": "",
    "text": "(First Published: May 17, 2023)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6a.html#learning-outcome",
    "href": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6a.html#learning-outcome",
    "title": "10 Ternary Plot to display composition of 3 variables",
    "section": "10.1 Learning Outcome",
    "text": "10.1 Learning Outcome\nWe will learn how to build ternary plot programmatically using R to visualise and analyse population structure of Singapore.\nTernary plots display the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point."
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6a.html#getting-started",
    "href": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6a.html#getting-started",
    "title": "10 Ternary Plot to display composition of 3 variables",
    "section": "10.2 Getting Started",
    "text": "10.2 Getting Started\n\n10.2.1 Install and load the required r libraries\nInstall and load the the required R packages. The name and function of the new package that will be used for this exercise is as follow:\n\nggtern, a ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\n\n\n\n\n\n\n\nNote on ggtern\n\n\n\nDue to some technical issue, ggtern is currently not available for downloading via cran. We need to download ggtern from the archive by using the code chunk below. The latest archive version is 3.4.1.\n\n\n\n\nShow the code\n# Codes below are used to install ggtern from archive\nrequire(devtools)\ninstall_version(\"ggtern\", version = \"3.4.1\", repos = \"http://cran.us.r-project.org\")\n\n\n(The codes above to install ggtern should only run once)\n\n\nShow the code\nlibrary(plotly)\nlibrary(tidyverse)\nlibrary(ggtern)\n\n\n\n\n10.2.2 Import the data\nFor the purpose of this hands-on exercise, the Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018 data will be used. The data set is called respopagsex2000to2018_tidy.csv and is in csv file format.\n\n\nShow the code\n#Reading the data into R environment\npop_data <- read_csv(\"data/respopagsex2000to2018_tidy.csv\", show_col_types = FALSE) \n\n\nNext, use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\n\nShow the code\n#Deriving the young, economy active and old measures\nagpop_mutated <- pop_data %>%\n  mutate(`Year` = as.character(Year))%>%\n  spread(AG, Population) %>%\n  mutate(YOUNG = rowSums(.[4:8]))%>%\n  mutate(ACTIVE = rowSums(.[9:16]))  %>%\n  mutate(OLD = rowSums(.[17:21])) %>%\n  mutate(TOTAL = rowSums(.[22:24])) %>%\n  filter(Year == 2018)%>%\n  filter(TOTAL > 0)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6a.html#plotting-static-ternary-diagram-with-ggtern",
    "href": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6a.html#plotting-static-ternary-diagram-with-ggtern",
    "title": "10 Ternary Plot to display composition of 3 variables",
    "section": "10.3 Plotting Static Ternary Diagram with ggtern",
    "text": "10.3 Plotting Static Ternary Diagram with ggtern\nWe can use ggtern() function of ggtern package to create a simple ternary plot.\n\n\nShow the code\n#Building the static ternary plot\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\nLet’s beautify the plot.\n\n\nShow the code\n#Building the static ternary plot\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"2018 Population Structure based on Subzones\") +\n  theme_rgbw()"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6a.html#plotting-intereactive-ternary-diagram-with-plotly",
    "href": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6a.html#plotting-intereactive-ternary-diagram-with-plotly",
    "title": "10 Ternary Plot to display composition of 3 variables",
    "section": "10.4 Plotting Intereactive Ternary Diagram with plotly",
    "text": "10.4 Plotting Intereactive Ternary Diagram with plotly\nWe can create an interactive ternary plot using plot_ly() function of Plotly R.\n🖱️Mouse over the dots below to check out the proportion of each population group for the subzones!\n\n\nShow the code\n# reusable function for creating annotation object\nlabel <- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 10,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 20, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis <- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes <- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD,\n  color = I(\"black\"), \n  type = \"scatterternary\",\n  text = ~SZ   # Added this argument to show the name of the subzone\n) %>%\n  layout(\n    annotations = label(\"2018 Population Structure\\nbased on Subzones\"), \n    ternary = ternaryAxes\n  ) \n\n\n\n\n\n\n\n\\(**That's\\) \\(all\\) \\(folks!**\\)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6b.html",
    "href": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6b.html",
    "title": "11 Visual Correlation Analysis of Numerical and Categorical Data",
    "section": "",
    "text": "(First published: May 17. 2023)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6b.html#learning-outcome",
    "href": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6b.html#learning-outcome",
    "title": "11 Visual Correlation Analysis of Numerical and Categorical Data",
    "section": "11.1 Learning Outcome",
    "text": "11.1 Learning Outcome\nWe will learn how to plot data visualisation for visualising correlation matrix with R using 3 methods:\n\nCreate correlation matrix using pairs() of R Graphics\nPlot corrgram using corrplot package of R\nCreate an interactive correlation matrix using plotly\n\nWhen multivariate data is used, the correlation coefficients of each pair of variables are displayed in a table form known as correlation matrix or scatterplot matrix.\nThere are three broad reasons for computing a correlation matrix:\n\nTo reveal the relationship between high-dimensional variables pair-wisely.\nAs input into other analyses. For example, people commonly use correlation matrices as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise.\nAs a diagnostic when checking other analyses. For example, with linear regression a high amount of correlations suggests that the linear regression’s estimates will be unreliable.\n\nWhen the data is large, both in terms of the number of observations and the number of variables, Corrgram tend to be used to visually explore and analyse the structure and the patterns of relations among variables. It is designed based on two main schemes:\n\nRendering the value of a correlation to depict its sign and magnitude, and\nReordering the variables in a correlation matrix so that “similar” variables are positioned adjacently, facilitating perception."
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6b.html#getting-started",
    "href": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6b.html#getting-started",
    "title": "11 Visual Correlation Analysis of Numerical and Categorical Data",
    "section": "11.2 Getting Started",
    "text": "11.2 Getting Started\n\n11.2.1 Install and load the required r libraries\nInstall and load the the required R packages. The name and function of the new package that will be used for this exercise is as follow:\n\ncorrplot : for creating correlation matrices and correlation plots\n\n\n\nShow the code\npacman::p_load(corrplot, ggstatsplot, tidyverse)\n\n\n11.2.2 Import the data\nWe will use the Wine Quality Data Set of UCI Machine Learning Repository. The data set consists of 13 variables and 6497 observations. For this exercise, we have combined the red wine and white wine data into one data file. It is called wine_quality and is in csv file format.\n\n\nShow the code\nwine <- read_csv(\"data/wine_quality.csv\", show_col_types = FALSE)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6b.html#building-correlation-matrix-with-pairsfunction",
    "href": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6b.html#building-correlation-matrix-with-pairsfunction",
    "title": "11 Visual Correlation Analysis of Numerical and Categorical Data",
    "section": "11.3 Building Correlation Matrix with pairs()function",
    "text": "11.3 Building Correlation Matrix with pairs()function\nWe can create a scatterplot matrix by using the pairs function of R Graphics.\n\n\nShow the code\npairs(wine[,1:11])\n\n\n\n\n\nThe required input of pairs() can be a matrix or data frame.\nColumns 2 to 12 of wine dataframe is used to build the next scatterplot matrix. The variables are: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates and alcohol.\n\n\nShow the code\npairs(wine[,2:12])\n\n\n\n\n\nDrawing the lower corner\npairs() function of R Graphics provided many customisation arguments. For example, it is a common practice to show either the upper half or lower half of the correlation matrix instead of both. This is because a correlation matrix is symmetric.\nTo show the lower half of the correlation matrix, the upper.panel argument will be used.\n\n\nShow the code\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\n\nSimilarly, we can display the upper half of the correlation matrix.\n\n\nShow the code\npairs(wine[,2:12], lower.panel = NULL)\n\n\n\n\n\nIncluding with correlation coefficients\nTo show the correlation coefficient of each pair of variables instead of a scatter plot, panel.cor() function will be used. This will also show higher correlations in a larger font.\n\n\nShow the code\npanel.cor <- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr <- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr <- abs(cor(x, y, use=\"complete.obs\"))\ntxt <- format(c(r, 0.123456789), digits=digits)[1]\ntxt <- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6b.html#visualise-correlation-matrix-using-ggcormat-function",
    "href": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6b.html#visualise-correlation-matrix-using-ggcormat-function",
    "title": "11 Visual Correlation Analysis of Numerical and Categorical Data",
    "section": "11.4 Visualise Correlation Matrix using ggcormat() function",
    "text": "11.4 Visualise Correlation Matrix using ggcormat() function\nOne of the major limitation of the correlation matrix is that the scatter plots appear very cluttered when the number of observations is relatively large (i.e. more than 500 observations). To overcome this problem, Corrgram data visualisation technique suggested by D. J. Murdoch and E. D. Chow (1996) and Friendly, M (2002) and will be used.\nThere are at least three R packages provide function to plot corrgram, they are:\n\ncorrgram\nellipse\ncorrplot\n\nOn top that, some R packages like ggstatsplot package also provides functions for building corrgram.\nIn this section, you will learn how to visualise correlation matrix by using ggcorrmat() of ggstatsplot package.\nThe basic plot\nggcorrmat() can provide a comprehensive and yet professional statistical report as shown in the figure below.\n\n\nShow the code\nset.seed(123)\nlibrary(ggcorrplot)\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11\n)\n\n\n\n\n\n\n\n\n\n\n\nOn ggcorrmat()\n\n\n\nThe ggcorrmat() function from the ggstatsplot package can conflict with the titleGrob() function from the ggpubr package. Both packages have functions with the same name, which is why we have to prefix the function with “ggstatsplot::”.\n\n\nLet’s touch up the plot.\n\n\nShow the code\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs of variables are not significant at p < 0.05\"\n)\n\n\n\n\n\nThings to note:\n\ncor.vars argument is used to compute the correlation matrix needed to build the corrgram.\nggcorrplot.args argument provide additional (mostly aesthetic) arguments that will be passed to ggcorrplot::ggcorrplot() function. The list should avoid any of the following arguments since they are already internally being used: corr, method, p.mat, sig.level, ggtheme, colors, lab, pch, legend.title, digits.\n\nThe following codes can be used to control specific components of the plot such as the font size of the x-axis, y-axis and the statistical report.\n\n\nShow the code\nggplot.component = list(\n    theme(text=element_text(size=5),\n      axis.text.x = element_text(size = 8),\n      axis.text.y = element_text(size = 8)))\n\n\nBuilding multiple plots\nSince ggstasplot is an extension of ggplot2, it also supports faceting. However the feature is not available in ggcorrmat() but in the grouped_ggcorrmat() of ggstatsplot.\n\n\nShow the code\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\n\nThings to note:\n\nto build a facet plot, the only argument needed is grouping.var.\nBehind group_ggcorrmat(), patchwork package is used to create the multiplot. plotgrid.args argument provides a list of additional arguments passed to patchwork::wrap_plots, except for guides argument which was separately specified earlier.\nLikewise, annotation.args argument is calling plot annotation arguments of patchwork package."
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6b.html#visualise-correlation-matrix-using-corrplot-package",
    "href": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6b.html#visualise-correlation-matrix-using-corrplot-package",
    "title": "11 Visual Correlation Analysis of Numerical and Categorical Data",
    "section": "11.5 Visualise Correlation Matrix Using corrplot package",
    "text": "11.5 Visualise Correlation Matrix Using corrplot package\nGetting started with corrplot Before we can plot a corrgram using corrplot(), we need to compute the correlation matrix of wine data frame. Thereafter, corrplot() is used to plot the corrgram by using all the default settings.\n\n\nShow the code\n# Compute the correlation matrix\nwine.cor <- cor(wine[, 1:11])\n\n# Create the basic corrplot\ncorrplot(wine.cor)\n\n\n\n\n\nNotice that the default visual object used to plot the corrgram is circle. The default layout of the corrgram is a symmetric matrix. The default colour scheme is diverging blue-red. Blue colours are used to represent pair variables with positive correlation coefficients and red colours are used to represent pair variables with negative correlation coefficients. The intensity of the colour or also know as saturation is used to represent the strength of the correlation coefficient. Darker colours indicate relatively stronger linear relationship between the paired variables. On the other hand, lighter colours indicates relatively weaker linear relationship.\nWorking with visual geometrics\nIn corrplot package, there are seven visual geometrics (parameter method) can be used to encode the attribute values. They are: circle, square, ellipse, number, shade, color and pie. The default is circle. As shown in the previous section, the default visual geometric of corrplot matrix is circle. However, this default setting can be changed by using the method argument.\n\n\nShow the code\ncorrplot(wine.cor, \n         method = \"ellipse\") \n\n\n\n\n\nWorking with layout\ncorrplor() supports three layout types, namely: “full”, “upper” or “lower”. The default is “full” which display full matrix. The default setting can be changed by using the type argument of corrplot().\n\n\nShow the code\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\")\n\n\n\n\n\nThe default layout of the corrgram can be further customised. For example, arguments diag and tl.col are used to turn off the diagonal cells and to change the axis text label colour to black colour respectively.\n\n\nShow the code\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\n\nWe can also experiment with other layout design argument such as tl.pos, tl.cex, tl.offset, cl.pos, cl.cex and cl.offset,\nWorking with mixed layout\nWith corrplot package, it is possible to design corrgram with mixed visual matrix of one half and numerical matrix on the other half. In order to create a coorgram with mixed layout, the corrplot.mixed(), a wrapped function for mixed visualisation style will be used.\n\n\nShow the code\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\nNotice that argument lower and upper are used to define the visualisation method used. In this case ellipse is used to map the lower half of the corrgram and numerical matrix (i.e. number) is used to map the upper half of the corrgram. The argument tl.pos, on the other, is used to specify the placement of the axis label. Lastly, the diag argument is used to specify the glyph on the principal diagonal of the corrgram.\n\n11.5.1 Combining corrgram with the significant test\nIn statistical analysis, we are also interested to know which pair of variables their correlation coefficients are statistically significant.\nThee figure below shows a corrgram combined with the significant test. The corrgram reveals that not all correlation pairs are statistically significant. For example the correlation between total sulfur dioxide and free sulfur dioxide is statistically significant at significant level of 0.1 but not the pair between total sulfur dioxide and citric acid.\nWe can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\n\nShow the code\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\n\nWe can then include the results in the p.mat argument of corrplot() function.\n\n\nShow the code\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n\nReorder a corrgram\nMatrix reorder is very important for mining the hiden structure and pattern in a corrgram. By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. “original”). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are:\n\n“AOE” is for the angular order of the eigenvectors. See Michael Friendly (2002) for details.\n“FPC” for the first principal component order.\n“hclust” for hierarchical clustering order, and “hclust.method” for the agglomeration method to be used.\n\n“hclust.method” should be one of “ward”, “single”, “complete”, “average”, “mcquitty”, “median” or “centroid”.\n\n“alphabet” for alphabetical order.\n\n“AOE”, “FPC”, “hclust”, “alphabet”. More algorithms can be found in seriation package.\n\n\nShow the code\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\nReordering a correlation matrix using hclust\nIf using hclust, corrplot() can draw rectangles around the corrgram based on the results of hierarchical clustering.\n\n\nShow the code\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6b.html#references",
    "href": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6b.html#references",
    "title": "11 Visual Correlation Analysis of Numerical and Categorical Data",
    "section": "11.6 References",
    "text": "11.6 References\n\nMichael Friendly (2002). “Corrgrams: Exploratory displays for correlation matrices”. The American Statistician, 56, 316–324.\nD.J. Murdoch, E.D. Chow (1996). “A graphical display of large correlation matrices”. The American Statistician, 50, 178–180."
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6c.html",
    "href": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6c.html",
    "title": "12 Heatmap to visualise Multivariate Data",
    "section": "",
    "text": "(First Published: May 18, 2023)"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6c.html#learning-outcome",
    "href": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6c.html#learning-outcome",
    "title": "12 Heatmap to visualise Multivariate Data",
    "section": "12.1 Learning Outcome",
    "text": "12.1 Learning Outcome\nWe will learn to plot static and interactive heatmap for visualising and analysing multivariate data.\nHeatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them."
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6c.html#getting-started",
    "href": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6c.html#getting-started",
    "title": "12 Heatmap to visualise Multivariate Data",
    "section": "12.2 Getting Started",
    "text": "12.2 Getting Started\n\n12.2.1 Install and load the required r libraries\nInstall and load the the required R packages. The name and function of the new packages that will be used for this exercise are as follow:\n\nseriation : includes various algorithms and methods for ordering objects and variables, such as hierarchical clustering-based seriation, matrix reordering, and optimal leaf ordering\nheatmaply : used for creating interactive and customizable heatmaps\ndendextend : for manipulating and enhancing dendrograms\n\n\n\nShow the code\npacman::p_load(seriation, dendextend, heatmaply, tidyverse)\n\n\n\n\n12.2.2 Import the data\nWe import the data set for World Happines 2018 report and assign it to wh.\n\n\nShow the code\n# Import data into R\nwh <- read_csv(\"data/WHData-2018.csv\", show_col_types = FALSE)\n\n\nTransform the data frame into a matrix\nWe need to transform the data frame to a data matrix to generate the heatmap. Before generating the data matrix, we will need to:\n\nSelect country and the relevant attributes which we are keen to visualise.\nChange the default row name (which is in a numeric series) to the country name.\n\n\n\nShow the code\n# Select country and attributes to visualise \nwh1 <- dplyr::select(wh, c(1,3, 7:12))\n\n# Set country column as rownames\nrow.names(wh1) <- wh1$Country\n\n# Generate the data matrix\nwh_matrix <- data.matrix(wh1) \n\n\nWe will exclude the country column from the data matrix since the information is now captured as row names.\n\n\nShow the code\nwh_matrix <- wh_matrix[,-1]"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6c.html#plot-static-heatmap",
    "href": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6c.html#plot-static-heatmap",
    "title": "12 Heatmap to visualise Multivariate Data",
    "section": "12.3 Plot static Heatmap",
    "text": "12.3 Plot static Heatmap\nThe R packages and functions for drawing static heatmaps are:\n\nheatmap() of R stats package. It draws a simple heatmap.\nheatmap.2() of gplots R package. It draws an enhanced heatmap compared to the R base function.\npheatmap() of pheatmap R package. pheatmap package also known as Pretty Heatmap. The package provides functions to draws pretty heatmaps and provides more control to change the appearance of heatmaps.\nComplexHeatmap package of R/Bioconductor package. The package draws, annotates and arranges complex heatmaps (very useful for genomic data analysis). The full reference guide of the package is available here.\nsuperheat package: A Graphical Tool for Exploring Complex Datasets Using Heatmaps. A system for generating extendable and customizable heatmaps for exploring complex datasets, including big data and data with multiple data types. The full reference guide of the package is available here.\n\nNext, we will learn how to plot static heatmaps by using heatmap() of R Stats package.\n\n\n\n\n\n\nNote\n\n\n\n\nBy default, heatmap() plots a cluster dendrogram heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\nIf we were to generate the default dendrogram heatmap (without specifying the Rowv and Colv arguments), the order of both rows and columns maybe be different from the plot below. This is because the dendrogram feature will do a reordering using clustering: it calculates the distance between each pair of rows and columns, and try to group and order them by similarity.\n\n\n\n\n\nShow the code\nwh_heatmap <- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA,\n                      cexRow = 0.6, \n                      cexCol = 0.6)\n\n\n\n\n\nThis heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns.\nThe plot below has its column-wise values normalised.\nNotice that the values are scaled now. Also note that margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively.\n\n\nShow the code\nwh_heatmap <- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.6,\n                      margins = c(10, 4))"
  },
  {
    "objectID": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6c.html#create-interactive-heatmap",
    "href": "Hands-On_Ex/Hands-On_Ex06/Hands-On_Ex6c.html#create-interactive-heatmap",
    "title": "12 Heatmap to visualise Multivariate Data",
    "section": "12.4 Create Interactive Heatmap",
    "text": "12.4 Create Interactive Heatmap\nheatmaply is an R package for building interactive cluster heatmap that can be shared online as a stand-alone HTML file. It is designed and maintained by Tal Galili.\n\n12.4.1 The basic plot with heatmaply\nWe will use heatmaply to design an interactive cluster heatmap. We will still use the wh_matrix as the input data.\n\n\n\n\n\n\nNote\n\n\n\nWe will extract a subset of 30 records from the wh_matrix to make it easier for us to see the effects of each tweak we are making to the plot.\n\n\n\n\nShow the code\nheatmaply(wh_matrix[1:30,],\n          cexRow = 0.6,\n          cexCol = 0.6)\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the right hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the left hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north.\n\n\n\n\n\n12.4.2 Data Transformation\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(), namely: scale, normalise and percentilse.\n\n12.4.2.1 Scaling\nWhen all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution. In such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling. In the plot behind, we scale variable values columewise.\n\n\nShow the code\nheatmaply(wh_matrix[1:30,],\n          scale = \"column\",\n          cexRow = 0.6,\n          cexCol = 0.6)\n\n\n\n\n\n\n\n\n12.4.2.2 Normalising\nWhen variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\nDifferent from Scaling, the normalise method is performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\n\nShow the code\nheatmaply(normalize(wh_matrix[1:30,]),\n          cexRow = 0.6,\n          cexCol = 0.6)\n\n\n\n\n\n\n\n\n12.4.2.3 Percentising\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nSimilar to Normalize method, the Percentize method is also performed on the input data set instead of using an argument.\n\n\nShow the code\nheatmaply(percentize(wh_matrix[1:30,]),\n          cexRow = 0.6,\n          cexCol = 0.6)\n\n\n\n\n\n\n\n\n\n12.4.3 Clustering algorithm\nheatmaply supports a variety of hierarchical clustering algorithms. The main arguments to provide are:\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. To use correlation-based clustering, we can use options “pearson”, “spearman” or “kendall”, which use as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\ndist_method: default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist”” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust_method default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically.\n\n12.4.3.1 Manual approach\nThe following heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\n\nShow the code\nheatmaply(normalize(wh_matrix[1:30,]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          cexRow = 0.6,\n          cexCol = 0.6)\n\n\n\n\n\n\n\n\n12.4.3.2 Statistical approach\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\n\nShow the code\nwh_d <- dist(normalize(wh_matrix[1:30,]), method = \"euclidean\")\n\nresults <- dend_expend(wh_d)[[3]]\n\nresults[order(-results$optim), ]\n\n\n  dist_methods hclust_methods     optim\n5      unknown        average 0.7814164\n6      unknown       mcquitty 0.7793163\n8      unknown       centroid 0.7680779\n3      unknown         single 0.7432104\n7      unknown         median 0.6990172\n4      unknown       complete 0.6959322\n2      unknown        ward.D2 0.5690666\n1      unknown         ward.D 0.4642559\n\n\nThe output table shows that “average” method should be used because it gives the highest optimum value. Next, find_k() is used to determine the optimal number of cluster.\n\n\nShow the code\nwh_clust <- hclust(wh_d, method = \"average\")\nnum_k <- find_k(wh_clust)\nplot(num_k)\n\n\n\n\n\nThe figure above shows that k=3 would be good.\nUsing the statistical analysis results, we can prepare the hierarchical plot.\n\n\nShow the code\nheatmaply(normalize(wh_matrix[1:30,]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3,\n          cexRow = 0.6,\n          cexCol = 0.6)\n\n\n\n\n\n\n\n\n\n12.4.4 Seriation\nOne problem with hierarchical clustering is that it doesn’t actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can’t end up between A and B, but it doesn’t tell you which way to flip the A+B cluster. It doesn’t tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying OLO to the same clustering result as the heatmap above.\n\n\nShow the code\nheatmaply(normalize(wh_matrix[1:30,]),\n          seriate = \"OLO\",\n          cexRow = 0.6,\n          cexCol = 0.6)\n\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\n\nShow the code\nheatmaply(normalize(wh_matrix[1:30,]),\n          seriate = \"GW\",\n          cexRow = 0.6,\n          cexCol = 0.6)\n\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\n\nShow the code\nheatmaply(normalize(wh_matrix[1:30,]),\n          seriate = \"mean\",\n          cexRow = 0.6,\n          cexCol = 0.6)\n\n\n\n\n\n\nThe option “none” gives us a dendrogram without any rotation that is based on the data matrix.\n\n\nShow the code\nheatmaply(normalize(wh_matrix[1:30,]),\n          seriate = \"none\",\n          cexRow = 0.6,\n          cexCol = 0.6)\n\n\n\n\n\n\n\n\n12.4.5 Working with color palettes\nThe default colour palette uses by heatmaply is viridis. We can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nWe use the Blues colour palette of rColorBrewer for the following plot.\n\n\nShow the code\nheatmaply(normalize(wh_matrix[1:30,]),\n          seriate = \"none\",\n          colors = Blues,\n          cexRow = 0.6,\n          cexCol = 0.6)\n\n\n\n\n\n\n\n\n12.4.6 The finishing touch\nBeside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 5.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\nWhich countries are clustered together with 🇸🇬?\n\n\nShow the code\nheatmaply(normalize(wh_matrix),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 5,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )\n\n\n\n\n\n\n\n\\(**That's\\) \\(all\\) \\(folks!**\\)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex01/In-Class_Ex1.html",
    "href": "In-Class_Ex/In-Class_Ex01/In-Class_Ex1.html",
    "title": "1 A Light Makeover of ggplots",
    "section": "",
    "text": "First published: 17-Apr-2023"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex01/In-Class_Ex1.html#learning-outcome",
    "href": "In-Class_Ex/In-Class_Ex01/In-Class_Ex1.html#learning-outcome",
    "title": "1 A Light Makeover of ggplots",
    "section": "1.1 Learning Outcome",
    "text": "1.1 Learning Outcome\nWe will:\n\nuse the graphic layers of ggplot2 to touch up various plots to make them more intuitive and appealing."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex01/In-Class_Ex1.html#getting-started",
    "href": "In-Class_Ex/In-Class_Ex01/In-Class_Ex1.html#getting-started",
    "title": "1 A Light Makeover of ggplots",
    "section": "1.2 Getting Started",
    "text": "1.2 Getting Started\n\n1.2.1 Install and load the required r libraries\nLoad the tidyverse library.\n\n\nShow the code\npacman::p_load(tidyverse)\n\n\n\n\n1.2.2 Import the data\nWe will be using the same exam scores data-set that was featured in my Hands-On Ex 1.\n\n\nShow the code\nexam_data <- read_csv('data/Exam_data.csv', show_col_types = FALSE )"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex01/In-Class_Ex1.html#candidates-for-makeover",
    "href": "In-Class_Ex/In-Class_Ex01/In-Class_Ex1.html#candidates-for-makeover",
    "title": "1 A Light Makeover of ggplots",
    "section": "1.3 Candidates for Makeover",
    "text": "1.3 Candidates for Makeover\n\n1.3.1 Working with theme\nWe can use the theme() function to change the colors of the plot panel background of the following plot to light blue and the color of grid lines to white. We will also include the title and subtitle to make the plot more meaningful.\n\nBeforeAfter\n\n\n\n\nShow the code\nggplot(data=exam_data, aes(x=RACE)) +\n  geom_bar() +\n  ylab('Count') +\n  theme_minimal() + \n  coord_flip()\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data=exam_data, aes(x=RACE)) +\n  geom_bar() +\n  ylab('Count') +\n  theme_minimal() + \n  coord_flip() +\n  \n  theme(\n    panel.background = element_rect(fill = \"lightblue\", colour = \"lightblue\"),\n    panel.grid.major = element_line(size = 0.75, linetype = 'solid', colour = \"white\"), \n    panel.grid.minor = element_line(size = 0.25, linetype = 'solid', colour = \"white\")\n      \n  ) +\n  \n  labs(title = \"Chinese Students Formed The Bulk Of The Cohort\",\n       subtitle = \"This was followed by Malay and Indian students\")\n\n\n\n\n\n\n\n\n\n\n1.3.2 Sort and label the columns in a chart\nFor the column chart displayed below, we have to address the following criticisms:\n\ny-axis title is not clear (i.e. count)\nTo support effective comparison, the bars should be sorted by their respective frequencies.\nFor static graph, frequency values should be added to provide addition information.\n\nTo address the first comment, we use ylab() and theme() function to relabel and calibrate the position of the y-axis title. For the 2nd and 3rd comment, we first summarise the data-set using group_by() and summarise() function to get the count of pupils by race. Thereafter, we use the reorder() function to sort the columns and geom_text() function to display the count.\n\nBeforeAfter\n\n\n\n\nShow the code\nggplot(data=exam_data, aes(x=RACE)) +\n  geom_bar() +\n  ylim(0,220) \n\n\n\n\n\n\n\n\n\nShow the code\n# Group the data by Race and aggregate by pupil count\nsorted_data <- exam_data %>% group_by(RACE) %>% summarise(count=n()) \n\n# Plot the chart\nggplot(data = sorted_data, aes(x=reorder(RACE, -count),y=count)) +\n  ylim(0,220) +\n  geom_col() +\n  ylab('No. of\\nPupils') +\n  theme(axis.title.y = element_text(angle = 0, vjust = 0.5, hjust=1))+\n  xlab('Race') +\n  geom_text(aes(label = count), vjust = -0.5, size = 3.5) +\n  labs(title = \"Chinese Pupils Formed The Bulk Of The Cohort\",\n       subtitle = \"This was followed by Malay and Indian pupils\")\n\n\n\n\n\n\n\n\n\n\n1.3.3 Add mean and median lines on the histogram\nWe can use the geom_vline() function to add a computed mean and median line onto the chart.\n\nBeforeAfter\n\n\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins = 20)\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  geom_vline(aes(xintercept=mean(MATHS, na.rm=T)),\n             color=\"red\", \n             linetype=\"dashed\", \n             size=1) +\n  geom_vline(aes(xintercept=median(MATHS, na.rm=T)),\n             color=\"grey30\",\n             linetype=\"dashed\", \n             size=1) +\n            xlab('Maths Score') +\n            ylab('Count') +\n  annotate(\"label\", color = \"red\", x=mean(exam_data$MATHS, na.rm=T)+2, y=50,\n          label=paste(\"Mean: \", round(mean(exam_data$MATHS, na.rm=T), 1)),fill = \"white\") +\n  annotate(\"label\",color=\"grey30\", x=median(exam_data$MATHS, na.rm=T)+2, y=40,\n          label=paste(\"Median: \", round(median(exam_data$MATHS, na.rm=T), 1)),fill = \"white\") + \n  labs(title = \"The Median score for Maths exam was 74\",\n         subtitle = \"We have a small porpotion of pupils who scored less than 25 marks\")\n\n\n\n\n\n\n\n\n\n\n1.3.4 Make the basic histogram more informative\nThe histograms below are elegantly designed but not informative. This is because they only reveal the distribution of English scores by gender but without context such as the score distribution for all pupils.\nTo show the distribution of English scores for all pupils as the background, we can add another geom_histogram() layer for all pupils.\n\nBeforeAfter\n\n\n\n\nShow the code\nggplot(data=exam_data, aes(x = ENGLISH )) +\n  geom_histogram() +\n  facet_wrap(~ GENDER) +\n  guides(fill = FALSE) \n\n\n\n\n\n\n\n\n\nShow the code\nd <- exam_data\n\n#create a d_bg dataframe without the gender attribute\nd_bg <- d[, -3]  \n\nggplot(d, aes(x = ENGLISH, fill = GENDER)) +\n  geom_histogram(data = d_bg, fill = \"grey\", alpha = .5) +\n  geom_histogram(colour = \"black\") +\n  facet_wrap(~ GENDER) +\n  # guides = false removes the legend from the chart\n  scale_fill_manual(values = c(\"Female\" = \"pink\", \"Male\" = \"light blue\")) +\n  guides(fill = FALSE) +  \n  theme_bw() +\n  labs(title = \"Female pupils scored higher marks than male pupils for English\",\n         subtitle = \"Their score distn covered the overall score distn for all pupuls on the right side fo the chart\")\n\n\n\n\n\n\n\n\n\n\n1.3.5 Dividing a chart into 4 quadrants\nWe can use geom_hline() and geom_vline() to divide the chart into equal quadrants (see After(1)). At the same time, we can use the coord_cartesian() function to adjust the limits of the coordinate system for a plot to only display the data that falls within those limits.\nIn After (2), I included a regression line and swtich the background to white (using theme_minimal()) to make the relationship between English and Math scores more prominent.\n\nBeforeAfter (1)After (2)\n\n\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x=MATHS, y=ENGLISH)) +\n  geom_point() +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(20,99))\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x=MATHS, y=ENGLISH)) +\n  geom_point() +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  geom_hline(yintercept=50,\n             linetype=\"dashed\",\n             color=\"grey60\",\n             size=1) + \n  geom_vline(xintercept=50, \n             linetype=\"dashed\",\n             color=\"grey60\",\n             size=1) +\n  labs(title = \"Pupils who did well in English tend to excel in Math as well\",\n         subtitle = \"There is a positive correlation between English and Math scores\") \n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data=exam_data, \n       aes(x=MATHS, y=ENGLISH)) +\n  geom_point() +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  geom_smooth(method=lm,linewidth=1.0)  +\n  labs(title = \"Pupils who did well in English tend to excel in Math as well\",\n         subtitle = \"There is a positive correlation between English and Math scores\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\\(**That's\\) \\(all\\) \\(folks!**\\)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex03/In-Class_Ex3.html",
    "href": "In-Class_Ex/In-Class_Ex03/In-Class_Ex3.html",
    "title": "2 Publishing a Quarto Document",
    "section": "",
    "text": "This test webpage was created as part of the follow-along exercise during Lesson 3."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex04/In-Class_Ex4.html",
    "href": "In-Class_Ex/In-Class_Ex04/In-Class_Ex4.html",
    "title": "3 Quantile–quantile plots",
    "section": "",
    "text": "(First published: May 6, 2023)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex04/In-Class_Ex4.html#load-the-required-packages",
    "href": "In-Class_Ex/In-Class_Ex04/In-Class_Ex4.html#load-the-required-packages",
    "title": "3 Quantile–quantile plots",
    "section": "1.Load the required packages",
    "text": "1.Load the required packages\n\n\nShow the code\npacman::p_load(rstatix,gt,patchwork,tidyverse,webshot2)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex04/In-Class_Ex4.html#load-the-data-set-into-r",
    "href": "In-Class_Ex/In-Class_Ex04/In-Class_Ex4.html#load-the-data-set-into-r",
    "title": "3 Quantile–quantile plots",
    "section": "2.Load the data-set into R",
    "text": "2.Load the data-set into R\n\n\nShow the code\nexam_data <- read_csv('data/Exam_data.csv', show_col_types = FALSE)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex04/In-Class_Ex4.html#visualise-normal-distribution",
    "href": "In-Class_Ex/In-Class_Ex04/In-Class_Ex4.html#visualise-normal-distribution",
    "title": "3 Quantile–quantile plots",
    "section": "3.Visualise Normal Distribution",
    "text": "3.Visualise Normal Distribution\nQuantile–quantile (Q-Q) plots are a useful visualization when we want to determine to what extent the observed data points do or do not follow a given distribution. If the data is normally distributed, the points in a Q-Q plot will be on a straight diagonally line. Conversely, if the points deviate significantly from the straight diagonally line, then it’s less likely that the data is normally distributed.\n\nThe PlotThe Codes\n\n\n\n\n\n\n\n\n\n\nggplot(exam_data, \n       aes(sample=ENGLISH))+\n  stat_qq()+\n  stat_qq_line()\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe can see that the points deviate significantly from the straight diagonal line. This is a clear indication that the set of data is not normally distributed."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex04/In-Class_Ex4.html#combining-statistical-graph-and-analysis-table",
    "href": "In-Class_Ex/In-Class_Ex04/In-Class_Ex4.html#combining-statistical-graph-and-analysis-table",
    "title": "3 Quantile–quantile plots",
    "section": "4.Combining statistical graph and analysis table",
    "text": "4.Combining statistical graph and analysis table\nWe will need to install webshot2\n\n\nShow the code\nqq <-ggplot(exam_data, \n       aes(sample=ENGLISH))+\n  stat_qq()+\n  stat_qq_line()\n\nsw_t <- exam_data %>%\n  shapiro_test(ENGLISH) %>%\n  gt()\n\ntmp <- tempfile(fileext = '.png')\ngtsave(sw_t,tmp)\ntable_png <- png::readPNG(tmp,\n                          native = TRUE)\n\nqq + table_png"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex5.html",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex5.html",
    "title": "4 Working with json files for Network Analysis",
    "section": "",
    "text": "(First Published: May 13, 2023)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex05/In-Class_Ex5.html#getting-started",
    "href": "In-Class_Ex/In-Class_Ex05/In-Class_Ex5.html#getting-started",
    "title": "4 Working with json files for Network Analysis",
    "section": "4.1 Getting Started",
    "text": "4.1 Getting Started\n\n4.1.1 Install and load the required r libraries\n\njsonlite : allows the reading and importing of json files.\n\n\n\nShow the code\npacman::p_load(jsonlite,tidygraph,ggraph,visNetwork,tidyverse)\n\n\n\n\n4.1.2 Import the data\nImport the given MC1.json file into R and assign the data to MC1.\n\n\nShow the code\nMC1 = fromJSON(\"data/MC1.json\")\n\n\nExtract the nodes info from MC1 data frame\n\n\nShow the code\nMC1_nodes <- as_tibble(MC1$nodes) %>%\n  select(id, type, country)\n\n\nExtract the edges info from MC1 data frame\n\n\nShow the code\nMC1_edges <- as_tibble(MC1$links) %>%\n  select(source, target, type, weight, key)\n\n\nAggregate the weight information between each pair of notes and by the relationship type\n\n\nShow the code\nMC1_edges_aggregated <- MC1_edges  %>%\n  group_by(source, target, type) %>%\n  summarise(weight_sum = sum()) %>%\n  filter(source !=target) %>%\n  ungroup()\n\n\n\n\n4.1.3 Use tbl_graph() to build tidygraph data model\nWe use tbl_graph() of tinygraph package to build an tidygraph's network graph data.frame.\n\n\nShow the code\nMC1_graph <- tbl_graph(nodes = MC1_nodes,\n                       edges = MC1_edges_aggregated,\n                       directed = TRUE)\n\n\nLet's take a look at the output tidygraph's graph object.\n\n\nShow the code\nMC1_graph\n\n\n# A tbl_graph: 3428 nodes and 10747 edges\n#\n# A bipartite multigraph with 93 components\n#\n# A tibble: 3,428 × 3\n  id                       type         country \n  <chr>                    <chr>        <chr>   \n1 Spanish Shrimp  Carriers company      Nalakond\n2 12744                    organization <NA>    \n3 143129355                organization <NA>    \n4 7775                     organization <NA>    \n5 1017141                  organization <NA>    \n6 2591586                  organization <NA>    \n# ℹ 3,422 more rows\n#\n# A tibble: 10,747 × 4\n   from    to type                weight_sum\n  <int> <int> <chr>                    <int>\n1    49    51 family_relationship          0\n2    49    52 family_relationship          0\n3    49     4 family_relationship          0\n# ℹ 10,744 more rows\n\n\nFurther data cleaning is required before we can proceed to plot the graph."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Visual Analytics and Applications",
    "section": "",
    "text": "I am a student taking a post-grad analytics programme. Welcome to my ISSS608 Visual Analytics and Applications site! 😊\nThis site is a portfolio of my learning and accomplishments in the course. It showcases the exercises and projects I have completed and the skills I have acquired from the course."
  },
  {
    "objectID": "Tableau/1_Superstore.html",
    "href": "Tableau/1_Superstore.html",
    "title": "Superstore Annual Sales and Profit",
    "section": "",
    "text": "This was the first dashboard we developed in class. It marks the start of our fascinating journey into the world of data visualisation using Tableau."
  },
  {
    "objectID": "Tableau/2_SuperStore_Story.html",
    "href": "Tableau/2_SuperStore_Story.html",
    "title": "The Superstore Story",
    "section": "",
    "text": "I created this storyboard after going through the online tutorial on Tableau’s website👻. It’s refreshing to learn some of the capabilities of the visualisation tool and the workflow of creating a data story"
  },
  {
    "objectID": "Tableau/3_Animation_CrossFiltering.html",
    "href": "Tableau/3_Animation_CrossFiltering.html",
    "title": "Animinated Bubble Plot and Cross-Filtering of Charts",
    "section": "",
    "text": "In line with the techniques covered under Hand-On Exercise 3a using R, , we were taught to create the following charts using Tableau this afternoon:\nA) An animated bubble plot using the Superstore data-set\n👇Select a different year using the “Year of Order Date’ radio buttons on the right to check out the animated transition.\n\n\nB) Cross-filtered Charts using Exam Scores data-set\n👇Select a group of data points on one of the three charts and notice how the other two charts respond dynamically.\n\n\nNeat right? 😉"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html",
    "title": "The City of Engagement: Undestanding the Demographics and Financial Characteristics of its Residents",
    "section": "",
    "text": "Photo: Hadi Zaher\n(First Published: May 14, 2023)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#setting-the-scene",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#setting-the-scene",
    "title": "The City of Engagement: Undestanding the Demographics and Financial Characteristics of its Residents",
    "section": "1.1 Setting the Scene",
    "text": "1.1 Setting the Scene\nCity of Engagement, with a total population of 50,000, is a small city located at Country of Nowhere. The city serves as a service centre of an agriculture region surrounding the city. The main agriculture of the region is fruit farms and vineyards.\nThe city council is in the process of preparing the Local Plan 2023. A sample survey of representative residents had been conducted to collect data related to their household demographic and spending patterns, among other things. The city aims to use the data to assist with their major community revitalization efforts, including how to allocate a very large city renewal grant they have recently received."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#our-task",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#our-task",
    "title": "The City of Engagement: Undestanding the Demographics and Financial Characteristics of its Residents",
    "section": "1.2 Our Task",
    "text": "1.2 Our Task\nWe are required to create a user-friendly and interactive solution to help city managers and planners to explore the complex data in an engaging way and reveal hidden patterns.\nTo this end, we will apply the concepts and methods learned from Lesson 1-4 of the course to reveal the demographic and financial characteristics of the city, using appropriate static and interactive statistical graphics methods."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#load-the-relevant-packages-into-the-r-environment",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#load-the-relevant-packages-into-the-r-environment",
    "title": "The City of Engagement: Undestanding the Demographics and Financial Characteristics of its Residents",
    "section": "2.1 Load the relevant packages into the R environment",
    "text": "2.1 Load the relevant packages into the R environment\nWe use the pacman::p_load() function to load the required R packages into our working environment. The loaded packages are:\n\nplotly: For creating interactive web-based graphs.\nggstatsplot: For creating graphics with details from statistical tests.\nggdist: For visualising distribution and uncertainty\nggthemes: Provides additional themes for ggplot2\ngridExtra: For combining multiple plots into a single plot\ntidyverse: A collection of core packages designed for data science, used extensively for data preparation and wrangling.\nDT: For creating interactive tables using the DataTables JavaScript library\nreshape2: For transforming dataframes from one shape to another\n\n\n\nShow the code\n#Load packages\npacman::p_load(plotly, ggstatsplot, ggdist, gridExtra,ggthemes, tidyverse, DT, reshape2)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#import-the-data-sets",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#import-the-data-sets",
    "title": "The City of Engagement: Undestanding the Demographics and Financial Characteristics of its Residents",
    "section": "2.2 Import the data-sets",
    "text": "2.2 Import the data-sets\nTwo data-sets are provided for this exercise:\n(i) Partcipants.csv: contains information about the 1011 city residents who responded to the survey. Other than an identifier variable, we also have the household size, a boolean indicator for households having children, age, education level, interest group and joviality (or happiness) level of the respondents.\nWe import the records in the Participants.csv file as survey, convert the participantId, householdSize and age from numeric to integer data type, and convert educationLevel from character data type to an ordinal factor.\n\n\nShow the code\n# Import Participant.csv and assign it to survey variable\nsurvey <- read_csv('data/Participants.csv', show_col_types = FALSE ) %>%\n  mutate(participantId = as.integer(participantId),\n         householdSize = as.integer(householdSize),\n         age = as.integer(age),\n         educationLevel = as.factor(educationLevel)\n         ) %>%\n  mutate(educationLevel = ordered(educationLevel, levels = c(\"Low\",\"HighSchoolOrCollege\", \"Bachelors\",\"Graduate\")))\n\n\n(ii) FinancialJournal.csv contains the financial transactions of the respondents from 1 Mar 2022 to 28 Feb 2023. Other than an identifier variable (which permits us to cross-reference to the participants’ demographic information), the time, nature and amount involved for the transactions were also provided.\nWe import the records in the FinancialJournal.csv file as financials, and convert the participantID from numeric to integer data type and round the amount values to 2 decimal point.\n\n\nShow the code\n# Import FinancialJournal.csv and assign it to financials variable\nfinancials <- read_csv('data/FinancialJournal.csv', show_col_types = FALSE) %>%\n  mutate(participantId = as.integer(participantId),\n         amount = round(amount,2)\n         )"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#create-a-month_year-column-for-temporal-analysis",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#create-a-month_year-column-for-temporal-analysis",
    "title": "The City of Engagement: Undestanding the Demographics and Financial Characteristics of its Residents",
    "section": "3.1 Create a month_year column for temporal analysis",
    "text": "3.1 Create a month_year column for temporal analysis\nThere are 1.5 million financial transactions over the 12-month period and the daily information is too granular for us to analyse. We will create a month_year column, from the timestamp column, which will then allow us to aggregate the transactions by month for temporal analysis.\n\n\nShow the code\n# Insert a month_year column\nfinancials <- financials %>%\n  mutate(month_year = format(timestamp, \"%b-%Y\")) %>%\n  mutate(month_year = as.factor(month_year)) %>%\n  mutate(month_year = ordered(month_year, levels = c(\"Mar-2022\", \"Apr-2022\",\"May-2022\",\"Jun-2022\",\"Jul-2022\",\"Aug-2022\",\"Sep-2022\",\"Oct-2022\",\"Nov-2022\", \"Dec-2022\",\"Jan-2023\",\"Feb-2023\")))"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#recode-rental-adjustments-as-part-of-shelter-expense",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#recode-rental-adjustments-as-part-of-shelter-expense",
    "title": "The City of Engagement: Undestanding the Demographics and Financial Characteristics of its Residents",
    "section": "3.2 Recode Rental Adjustments as part of Shelter Expense",
    "text": "3.2 Recode Rental Adjustments as part of Shelter Expense\nRent Adjustments do not occur frequently (only 131 transactions out of the 1.5 million financial transactions relate to RentAdjustment ) and they are essentially price adjustments associated with the cost of accommodation or rental refunds to the respondents.\n\n\nShow the code\n# Group and sumarise the transactions by category\nfinancials_grouped <- financials %>%\n  group_by(category) %>%\n  summarise(Count = n(), Sum_of_Amt = round(sum(amount),2)) \n\n# Display the results in tabular format and highliht RentalAdjustment transactions\ndatatable(financials_grouped, options = list(dom='t'), \n              caption = \"Table 1: Breakdown of Financial Journal Transactions By Category\",\n              rownames = FALSE) %>% \n    formatStyle(1,\n                target = 'row',\n                backgroundColor = styleEqual(c('RentAdjustment'), c('#c7e9c0')))\n\n\n\n\n\n\n\nAs such, Rent Adjustment transactions are recoded as Shelter in the financials table.\nAfter the recoding, the new breakdown of transactions by category is as follows:\n\n\nShow the code\n# Make a copy of the financials table \nfinancials_recoded <- financials\n\n# Recode all 'RentAdjustment' transactions to 'Shelter'\nfinancials_recoded$category <- ifelse(financials_recoded$category =='RentAdjustment','Shelter', financials_recoded$category)\n\n# Group and sumarise the transactions by category after recoding\nfinancials_grouped <- financials_recoded %>%\n  group_by(category) %>%\n  summarise(Count = n(), Sum_of_Amt = round(sum(amount),2)) \n\n# Display the results in tabular format and highliht Shelter transactions\ndatatable(financials_grouped, options = list(dom='t'), \n              caption = \"Table 2: New breakdown of Financial Journal Transactions By Category (after recoding)\",\n              rownames = FALSE) %>% \n    formatStyle(1,\n                target = 'row',\n                backgroundColor = styleEqual(c('Shelter'), c('#c7e9c0')))"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#remove-duplicate-records-found-in-the-financial-data",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#remove-duplicate-records-found-in-the-financial-data",
    "title": "The City of Engagement: Undestanding the Demographics and Financial Characteristics of its Residents",
    "section": "3.3 Remove duplicate records found in the financial data",
    "text": "3.3 Remove duplicate records found in the financial data\nWe notice duplicate records in the financial data. For instance, a survey participant (with Id=0) has duplicate records for Education and Shelter for the same amount and timestamp.\n\n\nShow the code\nparticipant_0 <- financials_recoded[,-5] %>% \n  filter(participantId=='0') %>%\n  group_by_all() %>%\n  filter(n()>1) %>%\n  arrange_all()\n  \n\ndatatable(participant_0, options = list(dom='t'), \n              caption = \"Table 3: Original and Duplicate Financial Records of a Survey Participant (Id=0)\",\n              rownames = FALSE) %>% \n  formatStyle(3,\n                target = 'row',\n                backgroundColor = styleEqual(c('Education'), c('#efedf5'))) %>%\n  formatStyle(3,\n                target = 'row',\n                backgroundColor = styleEqual(c('Shelter'), c('#9e9ac8')))\n\n\n\n\n\n\n\nApplying the duplicated() function on the financial data, we have:\n\n\nShow the code\npaste(sum(duplicated(financials_recoded)),\"duplicate records.\")\n\n\n[1] \"1113 duplicate records.\"\n\n\nWe are unsure of the reasons behind the duplicate records 😕. Nonetheless, we will use the distinct() function on the financial data to only retain unique records for our analysis.\n\n\nShow the code\nfinancials_unique <- financials_recoded %>%\n  distinct()"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#summarise-the-financial-information-by-participants",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#summarise-the-financial-information-by-participants",
    "title": "The City of Engagement: Undestanding the Demographics and Financial Characteristics of its Residents",
    "section": "3.4 Summarise the financial information by participants",
    "text": "3.4 Summarise the financial information by participants\nWe aggregate the financial information by participant, taking into consideration the timestamp and category using the dcast() function from reshape2 package.\nAfter performing the following steps, we notice 131 survey participants only have transaction records for Mar-2022 , but not in the other months :\n\nGroup the transactions by participantId, pivot the information by month_year and count the number of transactions per month\nAdd a new column, “Months_with_trans”, which sum up the no. of months over the 12-month period where there were transactions\nPerform a value count of the “Months_with_trans” column and this reveals the number of participants who only had 1 month of financial transactions.\n\n\n\nShow the code\n# Group the transactions by participantId, pivot the information by month_year and count the number of transactions per month.\nfinancials_count <- dcast(financials_unique,\n                           participantId ~ month_year, \n                           value.var = \"amount\", fun.aggregate = length)\n\n# Add a new column, \"Months_with_trans\", which sum up the no. of months over the 12-month period where there were transactions. \nfinancials_count$Months_with_trans <- apply(financials_count[,2:13]!=0,1,sum)\n\n# Perform a value count of the \"Months_with_trans\" column\nsummary_count <- financials_count %>%\n  group_by(Months_with_trans)%>%\n  summarise(Count=n())\n\ndatatable(summary_count, options = list(dom='t'), \n              caption = \"Table 4: No. of Survey Participants grouped by the count of months with transactions\",\n              rownames = FALSE) \n\n\n\n\n\n\n\nThe reason for the economic activity of the 131 participants appearing only in Mar-2022 is unclear and requires further investigation. To avoid biasing our results which covers the entire year, we will remove the records of these 131 participants from our subsequent analysis.\n\n\nShow the code\n# List those participants who only had transaction records for 1 month and assign it id_to_exclude\nids_to_exclude <- c(financials_count[financials_count$Months_with_trans==1,]$participantId)\n\n# Exclude from the financial_unique data-set participants whose id are in id_to_exclude list\nfinancials_880 <- subset(financials_unique, !(participantId %in% ids_to_exclude))\n\n\nNext, we derive the the monthly and total wages of the 880 participants. The first 5 records of the wage information are as follow:\n\n\nShow the code\nwages_880 <- \n  dcast(subset(financials_880,(category == 'Wage')), participantId ~ month_year, value.var = \"amount\", sum) %>%\n  mutate(total_wages = rowSums(.[2:13],na.rm=TRUE))\n\n\n# Inspect the first 5 records \ndatatable(head(wages_880, n=5), options = list(dom='t'), \n              caption = \"Table 5: First 5 records of the Monthly and Total Wages\",\n              rownames = FALSE) \n\n\n\n\n\n\n\nBased on Table 2 above, Education, Shelter, Food and Entertainment are all living expenses and we will also work out the monthly living expenses and the year’s total for the 880 participants. The first 5 records of the expenses information are as follow:\n\n\nShow the code\nexpenses_880 <- dcast(subset(financials_880,!(category == 'Wage')), participantId ~ month_year, value.var = \"amount\", sum) %>%\n  mutate(total_expenses = rowSums(.[2:13],na.rm=TRUE))\n\n# Inspect the first 5 records \ndatatable(head(expenses_880, n=5), options = list(dom='t'), \n              caption = \"Table 6: First 5 records of the Monthly and Total Expenses\",\n              rownames = FALSE)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#combine-the-participants-demographic-and-financial-data",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#combine-the-participants-demographic-and-financial-data",
    "title": "The City of Engagement: Undestanding the Demographics and Financial Characteristics of its Residents",
    "section": "3.5 Combine the participants’ demographic and financial data",
    "text": "3.5 Combine the participants’ demographic and financial data\nWe combine both sets of information into a single table (named as merged) and include 3 new columns:\n\ntotal_surplus : refers to the amount of wage surplus (or deficit) based on the difference between total wage and total expenses for the year.\nexpense_to_wage: the proportion of total expenses over total wages\nsurplus_to_wage: the proportion of total surplus over total wages\n\nfor our subsequent analysis.\nThe first 5 rows of the merged table are as follow:\n\n\nShow the code\nmerged <- survey %>% \n  inner_join(select(wages_880, participantId, total_wages), by = \"participantId\") %>%\n  inner_join(select(expenses_880, participantId, total_expenses), by = \"participantId\") %>%\n  mutate(total_surplus = total_wages + total_expenses,\n         expense_to_wage = round(abs(total_expenses/total_wages),3),\n         surplus_to_wage = round(total_surplus/total_wages,3)\n  )\n  \ndatatable(head(merged, n=5), options = list(dom='t'), \n              caption = \"Table 7: First 5 records of the Merged Demgraphic and Financial Data Table\",\n              rownames = FALSE)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#by-education-level",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#by-education-level",
    "title": "The City of Engagement: Undestanding the Demographics and Financial Characteristics of its Residents",
    "section": "4.1 By Education Level",
    "text": "4.1 By Education Level\n\n4.1.1 Breakdown on the proportion of participants by Education Level\n\n\n\n\n\n\nDesign Considerations for the Bar Plots\n\n\n\n\nSet a color scheme for each education level for consistency across mutliple charts\nProvide informative statistics about the participants for each education level in the tooltip. The content of the tips is customized through the aes() function within the geom_bar layer.\nUse plotly() for interactivity and displaying dynamic tooltip\n\n\n\n\n\nShow the code\nedu_prop <- merged %>%\n  group_by(educationLevel) %>%\n  summarise(count = n(),\n            avg_age = round(mean(age),0),\n            avg_hh = round(mean(householdSize),1),\n            avg_joviality = round(mean(joviality),3)) %>%\n  ungroup() %>%\n  mutate(proportion = count/sum(count))\n\n# Set a color scheme for Education Level analysis for consistency\ncolors <- c('#CCCCCC', '#808585', '#9067a7', '#ab6857')\n\nedu_col <- ggplot(edu_prop,aes(x = educationLevel, y = proportion, fill=educationLevel) ) +\n  geom_bar(stat = \"identity\",\n           aes(text = paste(\"Education Level:\", educationLevel,\n                              \"<br>Count:\", count,\n                              \"<br>Proportion:\", round(proportion*100,1), '%',\n                              \"<br>Average Age:\",avg_age,\n                              \"<br>Average Household Size:\", avg_hh,\n                              \"<br>Average Joviality:\", avg_joviality))) +\n  labs(x = \"Education Level\", \n       y = \"Proportion\", \n       title = \"93.6% of Participants receive College or Higher Level Education\",\n       subtitle = \"Most participants surveyed are literate\") +\n  # Set y-axis range from 0 to 0.50\n  scale_y_continuous(limits = c(0, 0.50)) +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  scale_fill_manual(values = colors) \n\n\nggplotly(edu_col, tooltip = 'text')\n\n\n\n\n\n\nFrom the above, we observe that majority of the participants have at least high school or college education. High literacy rate often correlates with higher knowledge-based economy and greater interest for cultural and intellectual activities. As we mouse over each column, we notice the following:\n\nAverage age across all education levels ranges from 38-40 years old\nAverage household size is around 2 persons\nHigher degree of joviality seems to be associated with higher education level.\n\n\n\n4.1.2 Distribution of total wages for the year by Education Level\n\n\n\n\n\n\nDesign Considerations for the Distribution Plots\n\n\n\n\nWith survey data, it’s useful to check the distribution of the data points for total wage and total expenses to get an intuition of how they differ for each education level. stat_halfeye() function is used to create half-density distribution for every education level\nA boxplot, created using geom_boxplot(), shows the median and mean values on the chart to complements the analysis\nThe x- and y- axes are switched around using the coord_flip()as it is easier to compare values horizontally\nThe stat_summary() function is used to add the marker for mean and text labels for median and mean values onto the chart\n\n\n\n\n\nShow the code\nggplot(merged, \n       aes(x = educationLevel, \n           y = total_wages)) +\n  stat_halfeye(aes(fill=educationLevel),\n               adjust = 1.0,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA,\n               alpha=0.5) +\n  coord_flip() +\n  theme_minimal() +\n  # Add geom_text layer for displaying median values\n  stat_summary(fun = median, geom = \"text\", aes(label = round(after_stat(y), 0)),\n               position = position_nudge(x = 0.15), vjust = -0.5,size=3) +\n  # Add geom_text layer for displaying mean dot in red\n  stat_summary(fun = mean, geom = \"point\", shape = 16, size = 3, color = \"#B00000\",\n               position = position_nudge(x = 0.0)) +\n  # Add geom_text layer for displaying mean values in red\n  stat_summary(fun = mean, geom = \"text\", aes(label = round(after_stat(y), 0)),\n               position = position_nudge(x = 0.15), vjust = 4, color = \"#B00000\",size=3) +\n  scale_fill_manual(values = colors) + \n  theme(legend.position = \"none\") + \n  scale_y_continuous(limits = c(0, 125000)) +\n  labs(x = \"Education Level\", \n       y = \"Total Wages for the Year($)\", \n       title = \"Participants who receive tertiary education earn considerably more\",\n       subtitle = \"\\n(Black fonts: Median Wage; Red fonts: Mean Wage)\") \n\n\n\n\n\nIt’s not surprising that the distribution of wages across all education levels are left-skewed. However, it’s worth noting that the wage distribution of participants who have tertiary education appear to be more evenly distributed than those who only receive College or lower education.\n\n\n4.1.3 Distribution of total expenses for the year by Education Level\nWith more income, does it mean that participants with tertiary education would spend more? Let’s find out!\n\n\nShow the code\nggplot(merged, \n       aes(x = educationLevel, \n           y = abs(total_expenses))) +\n  stat_halfeye(aes(fill=educationLevel),\n               adjust = 1.0,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA,\n               alpha = 0.5) +\n  # stat_dots(side = \"left\", \n  #           justification = 1.2, \n  #           binwidth = .5,\n  #           dotsize = 1.5) +\n  # Add'l codes from the previous plot\n  coord_flip() +\n  theme_minimal() +\n  # Add geom_text layer for displaying median values\n  stat_summary(fun = median, geom = \"text\", aes(label = round(after_stat(y), )),\n               position = position_nudge(x = 0.15), vjust = -0.5,size=3) +\n  # Add geom_text layer for displaying mean dot in red\n  stat_summary(fun = mean, geom = \"point\", shape = 16, size = 3, color = \"#B00000\",\n               position = position_nudge(x = 0.0)) +\n  stat_summary(fun = mean, geom = \"text\", aes(label = round(after_stat(y), 0)),\n               position = position_nudge(x = 0.15), vjust = 4, color = \"#B00000\",size=3) +\n  scale_fill_manual(values = colors) + \n  theme(legend.position = \"none\") + \n  labs(x = \"Education Level\", \n       y = \"Total Expenses for the Year($)\", \n       title = \"Participants Across All Education Levels Spend\\nbetween $15k and $17.5k on average\",\n       subtitle = \"\\n(Black fonts: Median Expenses; Red fonts: Mean Expenses)\") \n\n\n\n\n\nThe gap in expenses between the tertiary and non-tertiary educated participants is not as wide as their wages."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#by-household-size-and-kids",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#by-household-size-and-kids",
    "title": "The City of Engagement: Undestanding the Demographics and Financial Characteristics of its Residents",
    "section": "4.2 By Household Size and Kids",
    "text": "4.2 By Household Size and Kids\nLet’s check out some basic statistics on household size.\n\n4.2.1 Breakdown on the proportion of participants by Household Size\n\n\nShow the code\n# Set a color scheme for Household Size Level analysis for consistency\ncolors2 <- c('#CC9881', '#FADFC1', '#E3A6AB', '#A87B9F')\n\nhh_table <- merged %>%\n  group_by(householdSize,haveKids) %>%\n  summarise(count = n(),\n            avg_age = round(mean(age),0),\n            avg_joviality = round(mean(joviality),3)) %>%\n  ungroup() %>%\n  mutate(proportion = round(proportions(count),2)) %>%\n  select(householdSize,haveKids,count,proportion,avg_age,avg_joviality) %>%\n  mutate(householdSize = as.factor(householdSize))\n\nhh_bar <- ggplot(hh_table,aes(x = householdSize, y = proportion, fill=householdSize) ) +\n  geom_bar(stat = \"identity\",\n           aes(text = paste(\"Household Size:\", householdSize,\n                              \"<br>Have Kids:\", haveKids,\n                              \"<br>Count:\", count,\n                              \"<br>Proportion:\", round(proportion*100,1), '%',\n                              \"<br>Average Age:\",avg_age,\n                              \"<br>Average Joviality:\", avg_joviality))) +\n  labs(x = \"Household Size\", \n       y = \"Proportion\", \n       title = \"Fairly Proportionate Household Size with 1 to 3 Members\",\n       subtitle = \"\") +\n  # Set y-axis range from 0 to 0.40\n  scale_y_continuous(limits = c(0, 0.4)) +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  scale_fill_manual(values = colors2) \n\n\nggplotly(hh_bar, tooltip = 'text')\n\n\n\n\n\n\nFrom the above, we observe that household size is small and the distribution of family sizes is also fairly proportionate, with about one-third of households having 1, 2 or 3 members each. As we mouse over the each column, we notice the following:\n\nOnly households with the size of 3 have kids\nJoviality appears to be declining as the household size increases from 1 to 3\nSimilar to the split by education level, average age of participants across different household sizes ranges from 38 to 40 years old. This indicates that the age of participants in the survey is likely to be uniformly or normally distributed.\n\n\n\n4.2.2 Distribution of total wages for the year by Household Size\nLet’s examine the distribution of the participants’ wages across different household sizes.\n\n\nShow the code\nggplot(merged %>%\n      mutate(householdSize = as.factor(householdSize)), \n      aes(x = householdSize, \n           y = total_wages)) +\n  stat_halfeye(aes(fill=householdSize),\n               adjust = 1.0,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA,\n               alpha=0.5) +\n  coord_flip() +\n  theme_minimal() +\n  # Add geom_text layer for displaying median values\n  stat_summary(fun = median, geom = \"text\", aes(label = round(after_stat(y), 0)),\n               position = position_nudge(x = 0.15), vjust = -0.5,size=3) +\n  # Add geom_text layer for displaying mean dot in red\n  stat_summary(fun = mean, geom = \"point\", shape = 16, size = 3, color = \"#B00000\",\n               position = position_nudge(x = 0.0)) +\n  # Add geom_text layer for displaying mean values in red\n  stat_summary(fun = mean, geom = \"text\", aes(label = round(after_stat(y), 0)),\n               position = position_nudge(x = 0.15), vjust = 4, color = \"#B00000\",size=3) +\n  scale_fill_manual(values = colors2) + \n  theme(legend.position = \"none\") + \n  scale_y_continuous(limits = c(0, 125000)) +\n  labs(x = \"Household Size\", \n       y = \"Total Wages for the Year($)\", \n       title = \"Participants from Larger Houesholds Tend to Earn More\",\n       subtitle = \"\\n(Black fonts: Median Wage; Red fonts: Mean Wage)\") \n\n\n\n\n\nWhile larger households earn more, it is interesting to note that the average wage for 2- and 3-member households are comparable.\n\n\n4.2.3 Distribution of total expenses for the year by Household Size\nLet’s also find out if the participants from bigger households spend more as well.\n\n\nShow the code\nggplot(merged %>%\n      mutate(householdSize = as.factor(householdSize)),\n     aes(x = householdSize, \n           y = abs(total_expenses))) +\n  stat_halfeye(aes(fill=householdSize),\n               adjust = 1.0,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA,\n               alpha = 0.5) +\n  coord_flip() +\n  theme_minimal() +\n  # Add geom_text layer for displaying median values\n  stat_summary(fun = median, geom = \"text\", aes(label = round(after_stat(y), )),\n               position = position_nudge(x = 0.15), vjust = -0.5,size=3) +\n  # Add geom_text layer for displaying mean dot in red\n  stat_summary(fun = mean, geom = \"point\", shape = 16, size = 3, color = \"#B00000\",\n               position = position_nudge(x = 0.0)) +\n  stat_summary(fun = mean, geom = \"text\", aes(label = round(after_stat(y), 0)),\n               position = position_nudge(x = 0.15), vjust = 4, color = \"#B00000\",size=3) +\n  scale_fill_manual(values = colors2) + \n  theme(legend.position = \"none\") + \n  labs(x = \"Household Size\", \n       y = \"Total Expenses for the Year($)\", \n       title = \"Participants from Larger Houesholds Tend to Spend More As Well\",\n       subtitle = \"\\n(Black fonts: Median Expenses; Red fonts: Mean Expenses)\") \n\n\n\n\n\nSimilar to the observation for wages, 2- and 3- member households average spend is close to each other."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#overall-age-distribution",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#overall-age-distribution",
    "title": "The City of Engagement: Undestanding the Demographics and Financial Characteristics of its Residents",
    "section": "4.3 Overall Age Distribution",
    "text": "4.3 Overall Age Distribution\nEarlier on, we observed that the average age of participants ranges from 38-40 regardless of whether we slice the data by Education Level or Household Size. Visualising the age distribution of the participants would give us a sense of whether the population of the city is growing or ageing, which in turn has a social and economic implications to the city’s development.\n\n\n\n\n\n\nDesign Considerations for Histograms\n\n\n\n\nApply a simple design so that we focus on appreciating the “shape” of the distribution and get the “big” picture first.\nggplotly() is used to provide interactivity and details on the data.\n\n\n\n\n\nShow the code\nage_dist <- ggplot(data=merged, \n       aes(x= age)) +\n  geom_histogram(binwidth = 5, \n                 color=\"black\", \n                 fill='lightgray',\n                 linewidth = 0.1) +\n  xlim(c(15, 60)) +\n  ylim(c(0,150)) +\n  geom_vline(aes(xintercept=mean(age)),\n             color=\"red\", \n             linetype=\"dashed\", \n             size=1) +\n  geom_vline(aes(xintercept=median(age)),\n             color=\"grey30\",\n             linetype=\"dashed\", \n             size=1) +\n            xlab('Age') +\n            ylab('Count') +\n  ggtitle(\"Slow Population Growth in the City\") +\n  theme_minimal()\n\nggplotly(age_dist)\n\n\n\n\n\n\nThe relatively flat distribution for the age histogram above indicates slow population growth in the city, with the residents just reproducing enough to replace itself. Nonetheless, we have to check the survey’s participant identification criteria to ensure that the result above is not due to selection bias."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#overall-distribution-of-joviality-index",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#overall-distribution-of-joviality-index",
    "title": "The City of Engagement: Undestanding the Demographics and Financial Characteristics of its Residents",
    "section": "4.4 Overall Distribution of Joviality Index",
    "text": "4.4 Overall Distribution of Joviality Index\nIt is meaningful to assess the sentiments of the 880 participants who have been around in the past year, as this provides valuable insights into the well-being and quality of life of the participants. The joviality measure can be used to identify factors that contribute to happiness, thus allowing city planners to prioritise resources in areas that have a positive impact on residents’ well-being.\n\n\nShow the code\njoviality_dist <- ggplot(data=merged, \n       aes(x= joviality)) +\n  geom_histogram(bins = 20, \n                 color=\"black\", \n                 fill='lightgray',\n                 linewidth = 0.1) +\n  geom_vline(aes(xintercept=mean(joviality)),\n             color=\"red\", \n             linetype=\"dashed\", \n             size=1) +\n  geom_vline(aes(xintercept=median(joviality)),\n             color=\"grey30\",\n             linetype=\"dashed\", \n             size=1) +\n            xlab('Joviality Index') +\n            ylab('Count') +\n  ggtitle(\"The 880 Pariticipants are Moderately Unhappy 😐\") +\n  theme_minimal()\n\nggplotly(joviality_dist)\n\n\n\n\n\n\nWe can see that distribution of the joviality index is left-skewed and both the median and mean index values are at 0.44 and 0.47 respectively. This indicates that those surveyed are not too pleased with their quality of live in the city and it is worth investigating the factors that influence the index.\nHow about the 131 survey participants who were only around in Mar 2022? Did they leave because they were unhappy too?\nLet’s do a similar plot for them as well.\n\n\nShow the code\njoviality_dist_131 <- ggplot(data = survey %>%\n                               # Include this line to retrieve the records of the missing 131 participants\n                               filter(participantId %in% ids_to_exclude),\n                             aes(x = joviality)) +\n  geom_histogram(bins = 20, \n                 color = \"black\", \n                 fill = 'lightgray',\n                 linewidth = 0.1) +\n  geom_vline(aes(xintercept = mean(joviality)),\n             color = \"red\", \n             linetype = \"dashed\", \n             size = 1) +\n  geom_vline(aes(xintercept = median(joviality)),\n             color = \"grey30\",\n             linetype = \"dashed\", \n             size = 1) +\n  xlab('Joviality Index') +\n  ylab('Count') +\n  ggtitle(\"The 131 Missing Participants were Happier!!😕 \") +\n  theme_minimal()\n\n\nggplotly(joviality_dist_131)\n\n\n\n\n\n\nSurprisingly, the median and mean joviality index of the 131 participants who went “missing” after Mar 2022 is much higher. It’s definitely worth taking a deeper look into why this group of participants was happier."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#whether-a-higher-education-qualification-results-in-more-wages",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#whether-a-higher-education-qualification-results-in-more-wages",
    "title": "The City of Engagement: Undestanding the Demographics and Financial Characteristics of its Residents",
    "section": "5.1 Whether a higher education qualification results in more wages",
    "text": "5.1 Whether a higher education qualification results in more wages\nBefore we start validating our hypotheses, we will develop a function that will help us visualise if the data is normally distributed using a Quantile-Quantile (QQ) Plot. At the same time, we also want to conduct a Shapiro-Wilk Test for Normality to confirm that the data points really follow a normal distribution. The function will make the repetitive task of generating a normality test result for each data set easier.\n\n\n\n\n\n\nDesign Considerations for the Normality Test function\n\n\n\n\nAccept inputs for a dataframe, categorical variable and a continuous measure that we will be applying the normality test on.\nAccept inputs for the plot title and y-axis label.\nConvert non-categorical variable into one that is categorical and also obtain the unique values of the variable\nDraw a QQ plot based on the inputs\nCompute the p-value for the Shapiro-Wilk Test and indicate if the data set is normally distributed based on the significance level of 0.05.\nAnnotate the Shapiro-Wilk Test result on the top-left of the QQ Plot . To reduce clutter, it is sufficient to just show the p-value and the test outcome on the plot\nArrange all output plots in 2 columns\n\n\n\n\n\nShow the code\nnormality_test <- function(df, \n                            column, \n                            measure,\n                            title,\n                            ylabel) {\n  \n  category <- if (is.factor(df[[column]])) {\n    levels(df[[column]])\n  } else if (is.character(df[[column]])) {\n    sort(unique(df[[column]]))\n  } else {\n    sort(unique(as.character(df[[column]])))\n  }\n  \n  plots <- list()\n  color_counter <- 1\n  \n  for (class in category) {\n    \n    subset_df <- filter(df, !!sym(column) == class)\n    \n    shapiro_res <- shapiro.test(subset_df[[measure]])\n    \n    p_value <- format(shapiro_res$p.value, digits = 3)\n    is_normal <- ifelse(shapiro_res$p.value > 0.05, \"Yes\", \"No\")\n    \n    g <- ggplot(subset_df, aes(sample = !!sym(measure))) +\n      stat_qq() +\n      stat_qq_line() +\n      ggtitle(paste(title, class)) +\n      xlab(paste(column,':',class)) + \n      ylab(ylabel) +\n      theme_light() +\n      annotate(\"label\", x = -0.5, y = Inf, hjust = 1, vjust = 1.5, \n               label = paste(\"Shapiro-Wilk Normality Test:\", \"\\n\",\n                             \"p-value = \", p_value, \"\\n\",\n                             \"Is normal distn? \", is_normal),\n                fill = \"white\"\n                              ) \n    \n    plots[[class]] <- g\n  }\n  \n  grid.arrange(grobs = plots, ncol = 2)\n}\n\n\nStep1: For the Shapiro-Wilk Test, we hypothesize,\n\nH0 = The data is normally distributed at 0.05 level of significance\n\nWe run the function by providing the relevant parameters:\n\ndf : merged\ncolumn: ‘educationLevel’\nmeasure: ‘total_wages’\ntitle: “Normality Test on Total Wages’\nylabel: ‘Total Wages ($)’\n\n\n\nShow the code\nnormality_test(merged, 'educationLevel','total_wages',\"Normality Test on Total Wages for\",\"Total Wages($)\")\n\n\n\n\n\nThe results confirm that we can’t assume Normality for the data and we will proceed to apply a non-parametric test to check if the participants’ wages are different based on their education level.\nStep 2: For the nonparametric Kruskal-Willis Test, we hypothesize,\n\nH0 = There is no difference between the median total wage of the participants with different education level at 0.05 level of significance.\n\n\n\n\n\n\n\nDesign Consideration for the ANOVA Plot\n\n\n\n\nSet a non-parametric test\nEnable pairwise comparison and only display significant results\nDisable the display of Bayes Factor to reduce clutter\nEnable notch and set notch width since we are using Median\n\n\n\n\n\nShow the code\nset.seed(123)\n\n# Use a color scheme for Education Level analysis for consistency\ncolors <- c('#CCCCCC', '#808585', '#9067a7', '#ab6857')\n\nggbetweenstats(\n  data = merged,\n  x = educationLevel, \n  y = total_wages,\n  type = \"np\",\n  pairwise_comparisons=TRUE,\n  pairwise.display = \"s\",\n  bf.message = FALSE,\n  notch = TRUE,\n  notchwidth = 0.1,\n  ylab = \"Total Wages ($)\",\n  title = \"One-Way ANOVA on Total Wages \",\n  messages = FALSE\n)  +\n  scale_color_manual(values = colors) +\n  scale_y_continuous(limits = c(0, 300000))\n\n\n\n\n\nThe p-value of the Kruskal-Willis Test is < 0.05 and there is a statistically significant difference in total wages. This is further supported by the pairwise comparison of total wages between the education levels which shows significant differences in their wages among all levels.\nWith the above, we reject the null hypothesis and conclude that there is sufficient statistical evidence that the wages of participants with different education levels are different."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#whether-participants-with-higher-education-qualification-are-happier",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#whether-participants-with-higher-education-qualification-are-happier",
    "title": "The City of Engagement: Undestanding the Demographics and Financial Characteristics of its Residents",
    "section": "5.2 Whether participants with higher education qualification are happier",
    "text": "5.2 Whether participants with higher education qualification are happier\nWhile participants with higher education qualification receive more wages, does a better academic qualification translate to happiness?\nStep1: For the Shapiro-Wilk Test, we hypothesize,\n\nH0 = The Joviality Index data for each Education Level is normally distributed at 0.05 level of significance\n\n\n\nShow the code\nnormality_test(merged, 'educationLevel','joviality',\"Normality Test on Joviality Index for\",\"Joviality Index\")\n\n\n\n\n\nThe results confirm that we can’t assume Normality for the data and we will proceed to apply a non-parametric test.\nStep 2: For the nonparametric Kruskal-Willis Test, we hypothesize,\n\nH0 = There is no difference between the median joviality index of the participants with different education level at 0.05 level of significance.\n\n\n\nShow the code\nset.seed(123)\n\nggbetweenstats(\n  data = merged,\n  x = educationLevel, \n  y = joviality,\n  type = \"np\",\n  pairwise_comparisons=TRUE,\n  pairwise.display = \"s\",\n  bf.message = FALSE,\n  notch = TRUE,\n  notchwidth = 0.1,\n  ylab = \"Joviality Index\",\n  title = \"One-Way ANOVA on Joviality\",\n  messages = FALSE\n)  +\n  scale_color_manual(values = colors) +\n  # Increase the ylim > 1.0 so that the pairwise results can be displayed\n  scale_y_continuous(limits = c(0, 1.25))\n\n\n\n\n\nAlthough ANOVA test result show a p-value < 0.005 indicating that there is a difference in joviality among participants with different education levels and permitting us to reject the null hypothesis, this is mainly attributed to the significant difference between the joviality of participants who attended high school and graduate school."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#whether-having-children-result-in-higher-expenditure",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#whether-having-children-result-in-higher-expenditure",
    "title": "The City of Engagement: Undestanding the Demographics and Financial Characteristics of its Residents",
    "section": "5.3 Whether having children result in higher expenditure",
    "text": "5.3 Whether having children result in higher expenditure\nThis is a follow-up to the observation in Section 4.2 where we noticed households with kids have higher expenditures. We will proceed to validate this observation.\nStep1: For the Shapiro-Wilk Test, we hypothesize,\n\nH0 = The total expenses for households with and without kids is normally distributed at 0.05 level of significance\n\n\n\nShow the code\nnormality_test(merged, 'haveKids','total_expenses',\"Normality Test on Total Expenses Index for\",\"Total Expenses($)\")\n\n\n\n\n\nThe results confirm that we can’t assume Normality for the data and we will proceed to apply a non-parametric test for the 2 samples.\nStep 2: For the non-parametric Mann-Whitney Test, we hypothesize,\n\nH0 = There is no difference between the total expenses for households with and without kids at 0.05 level of significance.\n\n\n\nShow the code\nset.seed(123)\n\n# Set a color scheme for Household Size Level analysis for consistency\ncolors2 <- c('#FADFC1', '#E3A6AB', '#A87B9F')\n\nggbetweenstats(\n  data = merged %>%\n    mutate(total_expenses = abs(total_expenses)),\n  x = haveKids, \n  y = total_expenses,\n  type = \"np\",\n  pairwise_comparisons=TRUE,\n  pairwise.display = \"s\",\n  bf.message = FALSE,\n  notch = TRUE,\n  notchwidth = 0.1,\n  ylab = \"Total Expenses($)\",\n  title = \"2-Sample Non-Parametric Test on Total Expenses\",\n  messages = FALSE\n)  +\n  scale_color_manual(values = colors2) \n\n\n\n\n\nThe test results reveal that there is indeed a significant difference between the total expenses of participants who have kids and those who don’t and we will reject the null hypothesis.\nExpenses are made up of Education, Shelter, Food and Recreation. We will dive deeper to understand which of these expense types resulted in the significant difference in the expenditure of the 2 groups.\nTo do this, we have to first extract the individual expenses items of the 880 participants for the year before charting an interval plot by expense type.\n\n\n\n\n\n\nDesign Considerations for Interval Plot\n\n\n\n\nFor each expense item, we want to compare the spent by households with and without kids. To place each pair of interval lines together, we have to set the fill argument of the aes() function to the haveKids attribute, and set the position argument in the stat_pointinterval() function to ’position_dodge()’.\nSet point_interval argument as median quartile since data is not normally distributed\nAlign the color scheme with the previous plot by setting the values argument within the scale_fill_manual() function for consistency.\n\n\n\n\n\nShow the code\n# Extract the individual expenses items of the 880 participants for the year\n\nexpenses_by_id_category <- financials_880 %>%\n  filter(category != 'Wage') %>%\n  group_by(participantId, category) %>%\n  summarise(total_spent = sum(abs(amount))) %>%\n  inner_join(select(survey, participantId, haveKids), by = \"participantId\") \n\n# Prepare the interval plot\n\np<- expenses_by_id_category %>% \n  ggplot(aes(category, total_spent,fill=haveKids)) +\n  stat_pointinterval(\n    aes(interval_color = stat(fill)),\n    position = position_dodge(),\n    point_interval = median_qi,\n    .width = 0.95,\n    show.legend = TRUE\n    ) +\n  ylab(\"Total Spent ($)\") +\n  xlab(\"Expense Category\") +\n  theme_minimal() +\n  # Align the color scheme with the previou plot\n  scale_fill_manual(\n    values = c(\"#FADFC1\", \"#E3A6AB\"),\n    labels = c(\"FALSE\", \"TRUE\"),\n    guide = guide_legend(title = \"haveKids\"),\n    aesthetics = \"interval_color\") +\n  #Title, subtitle, and caption\n  labs(title = 'Visualising Uncertainty in Median Spend of Participants by Expense Type',\n  subtitle = '95% Quantiles intervals of median spend between participants With and WithOut kids') +\n  theme(plot.title = element_text(face = \"bold\", size = 14),\n        plot.subtitle = element_text(size = 10),\n        legend.position = \"top\") \n\np\n\n\n\n\n\nBased on the interval plot above, we see that all participants (with and without kids) have overlapping interval lines for food, recreation and shelter, indicating there is uncertainty on whether this is a significant difference in the median spend at 95% quantile for the 2 groups of participants on the 3 expense types.\nIt is also apparent that the spending on education , probably for the kids, is an expense item that participants without kids do not have to incur."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#whether-bigger-households-face-a-higher-burden-in-cost-of-living",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex1.html#whether-bigger-households-face-a-higher-burden-in-cost-of-living",
    "title": "The City of Engagement: Undestanding the Demographics and Financial Characteristics of its Residents",
    "section": "5.4 Whether bigger households face a higher burden in cost of living",
    "text": "5.4 Whether bigger households face a higher burden in cost of living\nWe will use the total expense to total wage ratio as a proxy measure for the cost of living in the city.\nStep1: For the Shapiro-Wilk Test, we hypothesize,\n\nH0 = The expense-to-wage ratio for different household sizes is normally distributed at 0.05 level of significance\n\n\n\nShow the code\nnormality_test(merged, 'householdSize','expense_to_wage',\"Normality Test on Expense To Wage Ratio for Household Size\",\"Expense-to-Wage Ratio\")\n\n\n\n\n\nSince we cannot assume Normality for the data based on the results of Step 1, we will apply non-parametric test to test the significance of the difference.\nStep 2: For the nonparametric Kruskal-Willis Test, we hypothesize,\n\nH0 = There is no difference between the expense-to-wage ratio of the participants with different household size at 0.05 level of significance.\n\n\n\nShow the code\nset.seed(123)\n\n# Set a color scheme for Household Size Level analysis for consistency\ncolors2 <- c('#CC9881', '#FADFC1', '#E3A6AB', '#A87B9F')\n\nggbetweenstats(\n  data = merged,\n  x = householdSize, \n  y = expense_to_wage,\n  type = \"np\",\n  pairwise_comparisons=TRUE,\n  pairwise.display = \"s\",\n  bf.message = FALSE,\n  notch = TRUE,\n  notchwidth = 0.1,\n  ylab = \"Expense-to-Wage Ratio\",\n  title = \"One-Way ANOVA on Expense-to-Wage Ratio\",\n  messages = FALSE\n)  +\n  scale_color_manual(values = colors2) \n\n\n\n\n\nThe p-value is > 0.05 indicating that there is insufficient evidence to reject the null hypothesis that the cost-to-wage ratio for larger households are different. Hence, we can also infer that even though we noticed families with kids incur higher expenses in Section 5.3, generally, the residents of these bigger households will earn more to defray the higher cost of living."
  }
]